{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Image_Classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWnbnDd1AqwK"
      },
      "source": [
        "# Simple CNN model for CIFAR-10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYpSkpfkAJ9c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Input, BatchNormalization\n",
        "from keras.constraints import maxnorm\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJpsavCTA0Dj"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCOqhYJqAxmj"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knMRFaZUBL8r"
      },
      "source": [
        "# Normalize inputs from 0-255 to 0.0-1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YH35TxjBJIH"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8GXS6V3vFiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4a22cd-1358-4371-8c7f-b7341966d018"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVTFI4SBTTU"
      },
      "source": [
        "# one hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqCaDjUBTwl"
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5B2yZL4vXom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df0c091-086c-41e8-9676-7c2edbcff6d3"
      },
      "source": [
        "print(num_classes)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PXbifxcBXdv"
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42jnKJGpBV-I"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(X_train.shape[1:]), padding='same', activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agtcn0FvBc50"
      },
      "source": [
        "# Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU0e5-U7Ba2q"
      },
      "source": [
        "epochs = 70\n",
        "lrate = 0.001\n",
        "sgd = Adam(learning_rate=lrate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPAxsGBWBgPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814d5fea-70b2-4fd4-bdf4-db786d156684"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               2097280   \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,117,962\n",
            "Trainable params: 2,117,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI3s6IHMBogK"
      },
      "source": [
        "# Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFS521-iBh-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5db8d9-fb0d-44db-858d-264d41af7651"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=128, verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "391/391 [==============================] - 7s 15ms/step - loss: 2.3004 - accuracy: 0.1502 - val_loss: 1.7548 - val_accuracy: 0.4070\n",
            "Epoch 2/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.7791 - accuracy: 0.3209 - val_loss: 1.5264 - val_accuracy: 0.4823\n",
            "Epoch 3/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.6468 - accuracy: 0.3727 - val_loss: 1.4228 - val_accuracy: 0.5150\n",
            "Epoch 4/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.5774 - accuracy: 0.4074 - val_loss: 1.4046 - val_accuracy: 0.5112\n",
            "Epoch 5/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.5344 - accuracy: 0.4302 - val_loss: 1.3537 - val_accuracy: 0.5536\n",
            "Epoch 6/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.4965 - accuracy: 0.4450 - val_loss: 1.2908 - val_accuracy: 0.5579\n",
            "Epoch 7/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.4579 - accuracy: 0.4577 - val_loss: 1.2531 - val_accuracy: 0.5745\n",
            "Epoch 8/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.4385 - accuracy: 0.4650 - val_loss: 1.2517 - val_accuracy: 0.5754\n",
            "Epoch 9/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.4066 - accuracy: 0.4812 - val_loss: 1.1961 - val_accuracy: 0.5891\n",
            "Epoch 10/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.3718 - accuracy: 0.4967 - val_loss: 1.2010 - val_accuracy: 0.5924\n",
            "Epoch 11/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.3533 - accuracy: 0.4989 - val_loss: 1.1852 - val_accuracy: 0.6139\n",
            "Epoch 12/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.3307 - accuracy: 0.5155 - val_loss: 1.1637 - val_accuracy: 0.6123\n",
            "Epoch 13/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.3107 - accuracy: 0.5152 - val_loss: 1.1134 - val_accuracy: 0.6206\n",
            "Epoch 14/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2936 - accuracy: 0.5249 - val_loss: 1.1067 - val_accuracy: 0.6315\n",
            "Epoch 15/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2710 - accuracy: 0.5309 - val_loss: 1.1203 - val_accuracy: 0.6154\n",
            "Epoch 16/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.2598 - accuracy: 0.5374 - val_loss: 1.1187 - val_accuracy: 0.6304\n",
            "Epoch 17/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.2594 - accuracy: 0.5373 - val_loss: 1.0935 - val_accuracy: 0.6432\n",
            "Epoch 18/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2459 - accuracy: 0.5424 - val_loss: 1.1218 - val_accuracy: 0.6349\n",
            "Epoch 19/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2440 - accuracy: 0.5430 - val_loss: 1.0876 - val_accuracy: 0.6429\n",
            "Epoch 20/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2248 - accuracy: 0.5515 - val_loss: 1.0526 - val_accuracy: 0.6470\n",
            "Epoch 21/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2235 - accuracy: 0.5504 - val_loss: 1.0534 - val_accuracy: 0.6478\n",
            "Epoch 22/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.2065 - accuracy: 0.5551 - val_loss: 1.0668 - val_accuracy: 0.6453\n",
            "Epoch 23/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1953 - accuracy: 0.5652 - val_loss: 1.0566 - val_accuracy: 0.6499\n",
            "Epoch 24/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1892 - accuracy: 0.5703 - val_loss: 1.0464 - val_accuracy: 0.6528\n",
            "Epoch 25/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.1721 - accuracy: 0.5762 - val_loss: 1.0219 - val_accuracy: 0.6632\n",
            "Epoch 26/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1585 - accuracy: 0.5807 - val_loss: 1.0072 - val_accuracy: 0.6702\n",
            "Epoch 27/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.1425 - accuracy: 0.5865 - val_loss: 1.0295 - val_accuracy: 0.6631\n",
            "Epoch 28/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.1446 - accuracy: 0.5806 - val_loss: 1.0207 - val_accuracy: 0.6626\n",
            "Epoch 29/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1319 - accuracy: 0.5896 - val_loss: 1.0203 - val_accuracy: 0.6551\n",
            "Epoch 30/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1290 - accuracy: 0.5864 - val_loss: 1.0037 - val_accuracy: 0.6707\n",
            "Epoch 31/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.1210 - accuracy: 0.5966 - val_loss: 1.0234 - val_accuracy: 0.6568\n",
            "Epoch 32/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1091 - accuracy: 0.5977 - val_loss: 0.9829 - val_accuracy: 0.6698\n",
            "Epoch 33/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0960 - accuracy: 0.6007 - val_loss: 0.9801 - val_accuracy: 0.6669\n",
            "Epoch 34/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0924 - accuracy: 0.6042 - val_loss: 0.9704 - val_accuracy: 0.6717\n",
            "Epoch 35/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0841 - accuracy: 0.6116 - val_loss: 0.9484 - val_accuracy: 0.6839\n",
            "Epoch 36/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0858 - accuracy: 0.6040 - val_loss: 0.9689 - val_accuracy: 0.6822\n",
            "Epoch 37/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0812 - accuracy: 0.6093 - val_loss: 0.9642 - val_accuracy: 0.6735\n",
            "Epoch 38/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0869 - accuracy: 0.6089 - val_loss: 0.9769 - val_accuracy: 0.6767\n",
            "Epoch 39/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0732 - accuracy: 0.6132 - val_loss: 0.9568 - val_accuracy: 0.6823\n",
            "Epoch 40/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0670 - accuracy: 0.6172 - val_loss: 0.9450 - val_accuracy: 0.6824\n",
            "Epoch 41/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0636 - accuracy: 0.6130 - val_loss: 0.9491 - val_accuracy: 0.6795\n",
            "Epoch 42/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0677 - accuracy: 0.6143 - val_loss: 0.9581 - val_accuracy: 0.6838\n",
            "Epoch 43/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0684 - accuracy: 0.6134 - val_loss: 0.9583 - val_accuracy: 0.6780\n",
            "Epoch 44/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0542 - accuracy: 0.6183 - val_loss: 0.9534 - val_accuracy: 0.6832\n",
            "Epoch 45/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0478 - accuracy: 0.6258 - val_loss: 0.9465 - val_accuracy: 0.6811\n",
            "Epoch 46/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0433 - accuracy: 0.6280 - val_loss: 0.9388 - val_accuracy: 0.6887\n",
            "Epoch 47/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0538 - accuracy: 0.6194 - val_loss: 0.9349 - val_accuracy: 0.6870\n",
            "Epoch 48/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0494 - accuracy: 0.6247 - val_loss: 0.9091 - val_accuracy: 0.6946\n",
            "Epoch 49/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0301 - accuracy: 0.6312 - val_loss: 0.9178 - val_accuracy: 0.6929\n",
            "Epoch 50/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0318 - accuracy: 0.6285 - val_loss: 0.9339 - val_accuracy: 0.6871\n",
            "Epoch 51/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0277 - accuracy: 0.6303 - val_loss: 0.9040 - val_accuracy: 0.6957\n",
            "Epoch 52/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0219 - accuracy: 0.6331 - val_loss: 0.9529 - val_accuracy: 0.6798\n",
            "Epoch 53/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0222 - accuracy: 0.6351 - val_loss: 0.9087 - val_accuracy: 0.6899\n",
            "Epoch 54/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0066 - accuracy: 0.6399 - val_loss: 0.9087 - val_accuracy: 0.6954\n",
            "Epoch 55/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0182 - accuracy: 0.6351 - val_loss: 0.9291 - val_accuracy: 0.6856\n",
            "Epoch 56/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0170 - accuracy: 0.6353 - val_loss: 0.9536 - val_accuracy: 0.6822\n",
            "Epoch 57/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0108 - accuracy: 0.6334 - val_loss: 0.9349 - val_accuracy: 0.6853\n",
            "Epoch 58/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0147 - accuracy: 0.6332 - val_loss: 0.9188 - val_accuracy: 0.6863\n",
            "Epoch 59/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 1.0101 - accuracy: 0.6353 - val_loss: 0.9207 - val_accuracy: 0.6903\n",
            "Epoch 60/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.0005 - accuracy: 0.6404 - val_loss: 0.9044 - val_accuracy: 0.6918\n",
            "Epoch 61/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0024 - accuracy: 0.6372 - val_loss: 0.9347 - val_accuracy: 0.6891\n",
            "Epoch 62/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 1.0003 - accuracy: 0.6408 - val_loss: 0.9225 - val_accuracy: 0.6920\n",
            "Epoch 63/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9957 - accuracy: 0.6450 - val_loss: 0.9159 - val_accuracy: 0.6970\n",
            "Epoch 64/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.9961 - accuracy: 0.6418 - val_loss: 0.9037 - val_accuracy: 0.7006\n",
            "Epoch 65/70\n",
            "391/391 [==============================] - 6s 14ms/step - loss: 0.9854 - accuracy: 0.6471 - val_loss: 0.9132 - val_accuracy: 0.6895\n",
            "Epoch 66/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9827 - accuracy: 0.6475 - val_loss: 0.9032 - val_accuracy: 0.6933\n",
            "Epoch 67/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9853 - accuracy: 0.6461 - val_loss: 0.8845 - val_accuracy: 0.6957\n",
            "Epoch 68/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9837 - accuracy: 0.6473 - val_loss: 0.9103 - val_accuracy: 0.6895\n",
            "Epoch 69/70\n",
            "391/391 [==============================] - 5s 14ms/step - loss: 0.9692 - accuracy: 0.6537 - val_loss: 0.8950 - val_accuracy: 0.6951\n",
            "Epoch 70/70\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 0.9687 - accuracy: 0.6508 - val_loss: 0.8790 - val_accuracy: 0.6985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35e8179850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5c_zYozCLFF"
      },
      "source": [
        "# Final evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7l-gnT2Bt1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130280cb-188b-4e32-96a3-6b9b2b58bcac"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Loss: %.2f%%\" %(scores[0]*100))\n",
        "print(\"Test Accuracy of existing model: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 87.90%\n",
            "Test Accuracy of existing model: 69.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWx7EoouDGrw"
      },
      "source": [
        "# 1. Follow the instruction below and then report how the performance changed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA1jghYEDToz"
      },
      "source": [
        "*   Convolutional input layer, 32 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "*   Dropout layer at 20%.\n",
        "*   Convolutional layer, 32 feature maps with a size of 3×3 and a rectifier  activation function.\n",
        "*   Max Pool layer with size 2×2.\n",
        "*   Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "*   Dropout layer at 20%.\n",
        "*   Convolutional layer, 64 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "*   Max Pool layer with size 2×2.\n",
        "*   Convolutional layer, 128 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "*   Dropout layer at 20%.\n",
        "*   Convolutional layer,128 feature maps with a size of 3×3 and a rectifier activation function.\n",
        "*   Max Pool layer with size 2×2.\n",
        "*   Flatten layer.\n",
        "*   Dropout layer at 20%.\n",
        "*   Fully connected layer with 1024 units and a rectifier activation function.\n",
        "*   Dropout layer at 20%.\n",
        "*   Fully connected layer with 512 units and a rectifier activation function.\n",
        "*   Dropout layer at 20%.\n",
        "*   Fully connected output layer with 10 units and a softmax activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQERa-cw-_xm"
      },
      "source": [
        "# Create model 2\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), input_shape=(X_train.shape[1:]), padding='same', activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSdFKRDD-meL"
      },
      "source": [
        "epochs = 70\n",
        "lrate = 0.001\n",
        "sgd = Adam(learning_rate=lrate)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozCCKGyQ-mq4",
        "outputId": "ed231b04-40df-4ac1-bf5b-678a7dbb4c0c"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 2,915,114\n",
            "Trainable params: 2,915,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbj9C5dQBaLm",
        "outputId": "4e8c56c0-c8f4-49d8-90e2-e6989b02ba04"
      },
      "source": [
        "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=128, verbose=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "391/391 [==============================] - 9s 19ms/step - loss: 1.9274 - accuracy: 0.2744 - val_loss: 1.3734 - val_accuracy: 0.5117\n",
            "Epoch 2/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 1.2771 - accuracy: 0.5355 - val_loss: 1.0522 - val_accuracy: 0.6316\n",
            "Epoch 3/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 1.0245 - accuracy: 0.6383 - val_loss: 0.9108 - val_accuracy: 0.6805\n",
            "Epoch 4/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.8712 - accuracy: 0.6903 - val_loss: 0.8167 - val_accuracy: 0.7142\n",
            "Epoch 5/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7717 - accuracy: 0.7289 - val_loss: 0.8005 - val_accuracy: 0.7217\n",
            "Epoch 6/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6907 - accuracy: 0.7568 - val_loss: 0.6918 - val_accuracy: 0.7604\n",
            "Epoch 7/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6293 - accuracy: 0.7797 - val_loss: 0.6872 - val_accuracy: 0.7622\n",
            "Epoch 8/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5907 - accuracy: 0.7926 - val_loss: 0.6412 - val_accuracy: 0.7794\n",
            "Epoch 9/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.5416 - accuracy: 0.8078 - val_loss: 0.6157 - val_accuracy: 0.7872\n",
            "Epoch 10/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5002 - accuracy: 0.8240 - val_loss: 0.6136 - val_accuracy: 0.7922\n",
            "Epoch 11/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4696 - accuracy: 0.8310 - val_loss: 0.6176 - val_accuracy: 0.7908\n",
            "Epoch 12/70\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.4437 - accuracy: 0.8408 - val_loss: 0.5845 - val_accuracy: 0.8014\n",
            "Epoch 13/70\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.4135 - accuracy: 0.8533 - val_loss: 0.6023 - val_accuracy: 0.7961\n",
            "Epoch 14/70\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.3926 - accuracy: 0.8611 - val_loss: 0.6201 - val_accuracy: 0.7917\n",
            "Epoch 15/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3799 - accuracy: 0.8624 - val_loss: 0.5914 - val_accuracy: 0.8063\n",
            "Epoch 16/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.3646 - accuracy: 0.8718 - val_loss: 0.5605 - val_accuracy: 0.8165\n",
            "Epoch 17/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3406 - accuracy: 0.8785 - val_loss: 0.5854 - val_accuracy: 0.8048\n",
            "Epoch 18/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.3316 - accuracy: 0.8809 - val_loss: 0.5703 - val_accuracy: 0.8124\n",
            "Epoch 19/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3174 - accuracy: 0.8870 - val_loss: 0.5690 - val_accuracy: 0.8189\n",
            "Epoch 20/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3104 - accuracy: 0.8895 - val_loss: 0.5762 - val_accuracy: 0.8156\n",
            "Epoch 21/70\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.3056 - accuracy: 0.8921 - val_loss: 0.5913 - val_accuracy: 0.8107\n",
            "Epoch 22/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2975 - accuracy: 0.8951 - val_loss: 0.5919 - val_accuracy: 0.8138\n",
            "Epoch 23/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2796 - accuracy: 0.9020 - val_loss: 0.5785 - val_accuracy: 0.8139\n",
            "Epoch 24/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2733 - accuracy: 0.9027 - val_loss: 0.5995 - val_accuracy: 0.8125\n",
            "Epoch 25/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2602 - accuracy: 0.9094 - val_loss: 0.5866 - val_accuracy: 0.8128\n",
            "Epoch 26/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2654 - accuracy: 0.9069 - val_loss: 0.5835 - val_accuracy: 0.8179\n",
            "Epoch 27/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2515 - accuracy: 0.9089 - val_loss: 0.6036 - val_accuracy: 0.8123\n",
            "Epoch 28/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2495 - accuracy: 0.9127 - val_loss: 0.5986 - val_accuracy: 0.8202\n",
            "Epoch 29/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2434 - accuracy: 0.9143 - val_loss: 0.6225 - val_accuracy: 0.8086\n",
            "Epoch 30/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2387 - accuracy: 0.9150 - val_loss: 0.6071 - val_accuracy: 0.8115\n",
            "Epoch 31/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2407 - accuracy: 0.9149 - val_loss: 0.6043 - val_accuracy: 0.8145\n",
            "Epoch 32/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2328 - accuracy: 0.9189 - val_loss: 0.6407 - val_accuracy: 0.8064\n",
            "Epoch 33/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2385 - accuracy: 0.9183 - val_loss: 0.5973 - val_accuracy: 0.8137\n",
            "Epoch 34/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2316 - accuracy: 0.9197 - val_loss: 0.5687 - val_accuracy: 0.8243\n",
            "Epoch 35/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2259 - accuracy: 0.9194 - val_loss: 0.6009 - val_accuracy: 0.8147\n",
            "Epoch 36/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2225 - accuracy: 0.9210 - val_loss: 0.5904 - val_accuracy: 0.8166\n",
            "Epoch 37/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2209 - accuracy: 0.9229 - val_loss: 0.6137 - val_accuracy: 0.8180\n",
            "Epoch 38/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2249 - accuracy: 0.9216 - val_loss: 0.6026 - val_accuracy: 0.8179\n",
            "Epoch 39/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2251 - accuracy: 0.9221 - val_loss: 0.5955 - val_accuracy: 0.8209\n",
            "Epoch 40/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2190 - accuracy: 0.9245 - val_loss: 0.6135 - val_accuracy: 0.8110\n",
            "Epoch 41/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2079 - accuracy: 0.9287 - val_loss: 0.5957 - val_accuracy: 0.8190\n",
            "Epoch 42/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2209 - accuracy: 0.9239 - val_loss: 0.6003 - val_accuracy: 0.8164\n",
            "Epoch 43/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2014 - accuracy: 0.9314 - val_loss: 0.6032 - val_accuracy: 0.8099\n",
            "Epoch 44/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2041 - accuracy: 0.9287 - val_loss: 0.6201 - val_accuracy: 0.8171\n",
            "Epoch 45/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2056 - accuracy: 0.9280 - val_loss: 0.5933 - val_accuracy: 0.8240\n",
            "Epoch 46/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1944 - accuracy: 0.9329 - val_loss: 0.5909 - val_accuracy: 0.8172\n",
            "Epoch 47/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1989 - accuracy: 0.9322 - val_loss: 0.5826 - val_accuracy: 0.8250\n",
            "Epoch 48/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2003 - accuracy: 0.9319 - val_loss: 0.6060 - val_accuracy: 0.8181\n",
            "Epoch 49/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2077 - accuracy: 0.9297 - val_loss: 0.5963 - val_accuracy: 0.8173\n",
            "Epoch 50/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2035 - accuracy: 0.9305 - val_loss: 0.6122 - val_accuracy: 0.8232\n",
            "Epoch 51/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1916 - accuracy: 0.9344 - val_loss: 0.5930 - val_accuracy: 0.8232\n",
            "Epoch 52/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1925 - accuracy: 0.9319 - val_loss: 0.6168 - val_accuracy: 0.8161\n",
            "Epoch 53/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.1937 - accuracy: 0.9324 - val_loss: 0.5751 - val_accuracy: 0.8288\n",
            "Epoch 54/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1865 - accuracy: 0.9367 - val_loss: 0.6053 - val_accuracy: 0.8253\n",
            "Epoch 55/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1942 - accuracy: 0.9332 - val_loss: 0.6403 - val_accuracy: 0.8146\n",
            "Epoch 56/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1910 - accuracy: 0.9344 - val_loss: 0.6082 - val_accuracy: 0.8209\n",
            "Epoch 57/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1856 - accuracy: 0.9357 - val_loss: 0.6057 - val_accuracy: 0.8225\n",
            "Epoch 58/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1822 - accuracy: 0.9366 - val_loss: 0.6354 - val_accuracy: 0.8172\n",
            "Epoch 59/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1947 - accuracy: 0.9326 - val_loss: 0.6305 - val_accuracy: 0.8222\n",
            "Epoch 60/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1849 - accuracy: 0.9376 - val_loss: 0.5952 - val_accuracy: 0.8256\n",
            "Epoch 61/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1906 - accuracy: 0.9336 - val_loss: 0.6008 - val_accuracy: 0.8215\n",
            "Epoch 62/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2013 - accuracy: 0.9315 - val_loss: 0.6050 - val_accuracy: 0.8248\n",
            "Epoch 63/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1873 - accuracy: 0.9369 - val_loss: 0.5996 - val_accuracy: 0.8257\n",
            "Epoch 64/70\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1872 - accuracy: 0.9355 - val_loss: 0.5931 - val_accuracy: 0.8224\n",
            "Epoch 65/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1773 - accuracy: 0.9407 - val_loss: 0.6261 - val_accuracy: 0.8239\n",
            "Epoch 66/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1811 - accuracy: 0.9371 - val_loss: 0.6441 - val_accuracy: 0.8156\n",
            "Epoch 67/70\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1803 - accuracy: 0.9396 - val_loss: 0.5879 - val_accuracy: 0.8206\n",
            "Epoch 68/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.1934 - accuracy: 0.9355 - val_loss: 0.6177 - val_accuracy: 0.8248\n",
            "Epoch 69/70\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.1888 - accuracy: 0.9346 - val_loss: 0.6161 - val_accuracy: 0.8247\n",
            "Epoch 70/70\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.1768 - accuracy: 0.9396 - val_loss: 0.5911 - val_accuracy: 0.8238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3600de2e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZupXRqEEECz3"
      },
      "source": [
        "# 2. Did the performance change?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSAOvEHJRIfp",
        "outputId": "9c3391af-a53f-432e-8e97-9894d0575f60"
      },
      "source": [
        "# Save the model\n",
        "model2.save('cifar10_model.h5')\n",
        "# Loading the model\n",
        "saved_model = load_model('cifar10_model.h5')\n",
        "\n",
        "# Model evaluation\n",
        "scores = saved_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy after adding Convolutional layers: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy after adding Convolutional layers: 82.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k26y8QpPMBf8"
      },
      "source": [
        "**Obeservation:** We see that there is an improvement in the accuracy after we added convolutional layers to the existing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRuMNA1BEF23"
      },
      "source": [
        "# 3. Change the previous model into Keras Functional API model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PVxUf3B-m0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11da4aad-3a0d-4640-a464-79aa150959df"
      },
      "source": [
        "(X_train, y_train), (X_val, y_val) = cifar10.load_data()\n",
        "X_train, X_val = X_train / 255.0, X_val / 255.0\n",
        "y_train, y_val = y_train.flatten(), y_val.flatten()\n",
        "\n",
        "i = Input(shape = X_train[0].shape)\n",
        "x = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(i)\n",
        "x = Conv2D(32, (3,3), activation=\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "x = Dropout(0.30)(x)\n",
        "x = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
        "x = Conv2D(64, (3,3), activation=\"relu\")(x)\n",
        "x = MaxPooling2D(pool_size=(2,2))(x)\n",
        "x = Dropout(0.30)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "api_model = Model(i, x)\n",
        "api_model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 6, 6, 64)          256       \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,251,114\n",
            "Trainable params: 1,250,986\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFG_p2fs-m-R"
      },
      "source": [
        "api_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjGHyAu2DHqI",
        "outputId": "69047880-22fd-4e72-fbac-d1b56b053a7b"
      },
      "source": [
        "api_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7719 - accuracy: 0.3639 - val_loss: 1.3274 - val_accuracy: 0.5361\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2219 - accuracy: 0.5643 - val_loss: 0.9987 - val_accuracy: 0.6477\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0538 - accuracy: 0.6323 - val_loss: 0.8544 - val_accuracy: 0.7005\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9619 - accuracy: 0.6594 - val_loss: 1.0066 - val_accuracy: 0.6530\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8974 - accuracy: 0.6859 - val_loss: 0.8414 - val_accuracy: 0.7104\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8464 - accuracy: 0.7020 - val_loss: 0.7693 - val_accuracy: 0.7349\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8134 - accuracy: 0.7158 - val_loss: 0.7788 - val_accuracy: 0.7364\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7797 - accuracy: 0.7235 - val_loss: 0.7337 - val_accuracy: 0.7461\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7494 - accuracy: 0.7365 - val_loss: 0.7525 - val_accuracy: 0.7380\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7331 - accuracy: 0.7415 - val_loss: 0.6632 - val_accuracy: 0.7707\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7115 - accuracy: 0.7530 - val_loss: 0.6529 - val_accuracy: 0.7770\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6878 - accuracy: 0.7572 - val_loss: 0.6438 - val_accuracy: 0.7756\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6792 - accuracy: 0.7633 - val_loss: 0.6500 - val_accuracy: 0.7776\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6681 - accuracy: 0.7685 - val_loss: 0.6794 - val_accuracy: 0.7652\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6530 - accuracy: 0.7714 - val_loss: 0.6261 - val_accuracy: 0.7882\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6446 - accuracy: 0.7742 - val_loss: 0.6676 - val_accuracy: 0.7692\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6346 - accuracy: 0.7769 - val_loss: 0.6676 - val_accuracy: 0.7760\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6187 - accuracy: 0.7825 - val_loss: 0.6143 - val_accuracy: 0.7913\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6165 - accuracy: 0.7860 - val_loss: 0.7138 - val_accuracy: 0.7619\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5970 - accuracy: 0.7904 - val_loss: 0.6164 - val_accuracy: 0.7901\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6016 - accuracy: 0.7892 - val_loss: 0.5880 - val_accuracy: 0.8012\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5876 - accuracy: 0.7931 - val_loss: 0.6160 - val_accuracy: 0.7960\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5805 - accuracy: 0.7962 - val_loss: 0.6475 - val_accuracy: 0.7770\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5765 - accuracy: 0.8000 - val_loss: 0.6118 - val_accuracy: 0.7940\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5695 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.8040\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5688 - accuracy: 0.8000 - val_loss: 0.5975 - val_accuracy: 0.8025\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5605 - accuracy: 0.8034 - val_loss: 0.5756 - val_accuracy: 0.8053\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5489 - accuracy: 0.8072 - val_loss: 0.5871 - val_accuracy: 0.8016\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5409 - accuracy: 0.8129 - val_loss: 0.6188 - val_accuracy: 0.7883\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5535 - accuracy: 0.8074 - val_loss: 0.5775 - val_accuracy: 0.8066\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5389 - accuracy: 0.8119 - val_loss: 0.5831 - val_accuracy: 0.8067\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5363 - accuracy: 0.8097 - val_loss: 0.6127 - val_accuracy: 0.7932\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5271 - accuracy: 0.8143 - val_loss: 0.5663 - val_accuracy: 0.8109\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5212 - accuracy: 0.8183 - val_loss: 0.5730 - val_accuracy: 0.8053\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5237 - accuracy: 0.8182 - val_loss: 0.5882 - val_accuracy: 0.8068\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5286 - accuracy: 0.8146 - val_loss: 0.6171 - val_accuracy: 0.8008\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5132 - accuracy: 0.8195 - val_loss: 0.6469 - val_accuracy: 0.7883\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5233 - accuracy: 0.8160 - val_loss: 0.5773 - val_accuracy: 0.8086\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5072 - accuracy: 0.8208 - val_loss: 0.5768 - val_accuracy: 0.8098\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5056 - accuracy: 0.8227 - val_loss: 0.5744 - val_accuracy: 0.8123\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4998 - accuracy: 0.8267 - val_loss: 0.5716 - val_accuracy: 0.8109\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5105 - accuracy: 0.8196 - val_loss: 0.5899 - val_accuracy: 0.8046\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4903 - accuracy: 0.8289 - val_loss: 0.5626 - val_accuracy: 0.8154\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4965 - accuracy: 0.8249 - val_loss: 0.5732 - val_accuracy: 0.8095\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4956 - accuracy: 0.8249 - val_loss: 0.5751 - val_accuracy: 0.8120\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4852 - accuracy: 0.8301 - val_loss: 0.5982 - val_accuracy: 0.7993\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4937 - accuracy: 0.8278 - val_loss: 0.5579 - val_accuracy: 0.8117\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4694 - accuracy: 0.8321 - val_loss: 0.5598 - val_accuracy: 0.8139\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4810 - accuracy: 0.8319 - val_loss: 0.5610 - val_accuracy: 0.8123\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4815 - accuracy: 0.8325 - val_loss: 0.5528 - val_accuracy: 0.8204\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4714 - accuracy: 0.8341 - val_loss: 0.5706 - val_accuracy: 0.8102\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4624 - accuracy: 0.8358 - val_loss: 0.5517 - val_accuracy: 0.8173\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4653 - accuracy: 0.8359 - val_loss: 0.5838 - val_accuracy: 0.8068\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4627 - accuracy: 0.8374 - val_loss: 0.5475 - val_accuracy: 0.8144\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4690 - accuracy: 0.8357 - val_loss: 0.5741 - val_accuracy: 0.8103\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4648 - accuracy: 0.8396 - val_loss: 0.5596 - val_accuracy: 0.8181\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4638 - accuracy: 0.8371 - val_loss: 0.5672 - val_accuracy: 0.8112\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4649 - accuracy: 0.8342 - val_loss: 0.5472 - val_accuracy: 0.8211\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4485 - accuracy: 0.8392 - val_loss: 0.5404 - val_accuracy: 0.8203\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4611 - accuracy: 0.8373 - val_loss: 0.5347 - val_accuracy: 0.8234\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4455 - accuracy: 0.8413 - val_loss: 0.5924 - val_accuracy: 0.8010\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4572 - accuracy: 0.8403 - val_loss: 0.5585 - val_accuracy: 0.8125\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4448 - accuracy: 0.8447 - val_loss: 0.5522 - val_accuracy: 0.8228\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4395 - accuracy: 0.8461 - val_loss: 0.5462 - val_accuracy: 0.8205\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4473 - accuracy: 0.8448 - val_loss: 0.5550 - val_accuracy: 0.8182\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4461 - accuracy: 0.8418 - val_loss: 0.5377 - val_accuracy: 0.8205\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4369 - accuracy: 0.8480 - val_loss: 0.5431 - val_accuracy: 0.8207\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4441 - accuracy: 0.8442 - val_loss: 0.5435 - val_accuracy: 0.8190\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4437 - accuracy: 0.8446 - val_loss: 0.5448 - val_accuracy: 0.8165\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4395 - accuracy: 0.8480 - val_loss: 0.5386 - val_accuracy: 0.8213\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4393 - accuracy: 0.8447 - val_loss: 0.5380 - val_accuracy: 0.8219\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4341 - accuracy: 0.8476 - val_loss: 0.5570 - val_accuracy: 0.8154\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4252 - accuracy: 0.8505 - val_loss: 0.5440 - val_accuracy: 0.8174\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4230 - accuracy: 0.8527 - val_loss: 0.5559 - val_accuracy: 0.8145\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4296 - accuracy: 0.8491 - val_loss: 0.5615 - val_accuracy: 0.8167\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4252 - accuracy: 0.8515 - val_loss: 0.5554 - val_accuracy: 0.8206\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4226 - accuracy: 0.8517 - val_loss: 0.5356 - val_accuracy: 0.8243\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4172 - accuracy: 0.8531 - val_loss: 0.5534 - val_accuracy: 0.8192\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4276 - accuracy: 0.8498 - val_loss: 0.5721 - val_accuracy: 0.8153\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4233 - accuracy: 0.8528 - val_loss: 0.5812 - val_accuracy: 0.8103\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4265 - accuracy: 0.8528 - val_loss: 0.5752 - val_accuracy: 0.8128\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4214 - accuracy: 0.8523 - val_loss: 0.5424 - val_accuracy: 0.8212\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4171 - accuracy: 0.8515 - val_loss: 0.5492 - val_accuracy: 0.8215\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4296 - accuracy: 0.8473 - val_loss: 0.5526 - val_accuracy: 0.8207\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4141 - accuracy: 0.8540 - val_loss: 0.5733 - val_accuracy: 0.8099\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4240 - accuracy: 0.8496 - val_loss: 0.5459 - val_accuracy: 0.8202\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4183 - accuracy: 0.8512 - val_loss: 0.5588 - val_accuracy: 0.8126\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4158 - accuracy: 0.8545 - val_loss: 0.5599 - val_accuracy: 0.8123\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4076 - accuracy: 0.8584 - val_loss: 0.5927 - val_accuracy: 0.8104\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4105 - accuracy: 0.8572 - val_loss: 0.5558 - val_accuracy: 0.8189\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4182 - accuracy: 0.8531 - val_loss: 0.5987 - val_accuracy: 0.8083\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4145 - accuracy: 0.8539 - val_loss: 0.5458 - val_accuracy: 0.8180\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4049 - accuracy: 0.8602 - val_loss: 0.5706 - val_accuracy: 0.8128\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3976 - accuracy: 0.8599 - val_loss: 0.5446 - val_accuracy: 0.8207\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3988 - accuracy: 0.8590 - val_loss: 0.5429 - val_accuracy: 0.8182\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4045 - accuracy: 0.8576 - val_loss: 0.5734 - val_accuracy: 0.8163\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4049 - accuracy: 0.8578 - val_loss: 0.5491 - val_accuracy: 0.8188\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4049 - accuracy: 0.8595 - val_loss: 0.5520 - val_accuracy: 0.8198\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4092 - accuracy: 0.8567 - val_loss: 0.5522 - val_accuracy: 0.8190\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.4061 - accuracy: 0.8558 - val_loss: 0.5607 - val_accuracy: 0.8139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35e80cffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7ziofE8WRXY"
      },
      "source": [
        "# Save the model\n",
        "api_model.save('api_model.h5')\n",
        "# Loading the model\n",
        "api_saved_model = load_model('api_model.h5')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSAhZ8qnA1Q9",
        "outputId": "5e1f958f-3e92-4383-b538-0323dd63e315"
      },
      "source": [
        "# Model evaluation\n",
        "scores = api_saved_model.evaluate(X_val, y_val, verbose=0)\n",
        "print(\"Test Accuracy for functional API model: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy for functional API model: 81.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Qm8QtkDCcM"
      },
      "source": [
        "# 4. Predict the first 4 image of the test data. Then, print the actual label for those 4 images (label means the probability associated with them) to check if the model predicted correctly or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJOr6qp4EQxf"
      },
      "source": [
        "classes = ['airplaine', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v64PLUcyEQ4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4752488f-ab2e-4795-b9b3-480713a00d79"
      },
      "source": [
        "fig = plt.figure(figsize=(25, 4))\n",
        "#fig, ax = plt.subplots()\n",
        "for idx in range(4):\n",
        "  ax = fig.add_subplot(1, 4, idx+1)\n",
        "  ax.imshow(X_test[idx])\n",
        "  y_pred = np.argmax(saved_model.predict(np.expand_dims(X_test[idx], axis=0)), axis=1)\n",
        "  y_actual= np.argmax(y_test[idx])\n",
        "  ax.set_title(\"{} ({})\".format(classes[y_pred.item()], classes[y_actual]), color=(\"green\" if y_pred.item()== y_actual else \"red\"))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PpdCh2oWpES"
      },
      "source": [
        "**Observation:** We see that the new model is correctly predicting all the first 4 images in the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ijTkh5w0Kxw"
      },
      "source": [
        "# 6. Apply the following callbacks:\n",
        "*   ModelCheckPoint\n",
        "*   EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQEwJ2L0ama"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# generate 2d classification dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# scale the data\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One hot label encoding\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRIHxW3pwlpt"
      },
      "source": [
        "# Create model new model\n",
        "new_model = Sequential()\n",
        "new_model.add(Conv2D(32, (3, 3), input_shape=(X_train.shape[1:]), padding='same', activation='relu'))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "new_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "new_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "new_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "new_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "new_model.add(Flatten())\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Dense(512, activation='relu'))\n",
        "new_model.add(Dropout(0.2))\n",
        "new_model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSgZArtBwfAm"
      },
      "source": [
        "l_rate = 0.001\n",
        "sgd = Adam(learning_rate=l_rate)\n",
        "new_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "153erMI00m1R"
      },
      "source": [
        "## Apply EarlyStopping and ModelCheckpoint callbacks and fit the new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imx9RsVCwX5k",
        "outputId": "cd3cb355-3a31-4b75-eaf1-013bcc2b3658"
      },
      "source": [
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "\n",
        "# apply Model checkpointing\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "# Fit the model\n",
        "new_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 9s 19ms/step - loss: 2.0249 - accuracy: 0.2329 - val_loss: 1.4879 - val_accuracy: 0.4658\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.46580, saving model to best_model.h5\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 1.4556 - accuracy: 0.4636 - val_loss: 1.3033 - val_accuracy: 0.5400\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.46580 to 0.54000, saving model to best_model.h5\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 1.2458 - accuracy: 0.5532 - val_loss: 1.0756 - val_accuracy: 0.6248\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.54000 to 0.62480, saving model to best_model.h5\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 1.0492 - accuracy: 0.6225 - val_loss: 0.9896 - val_accuracy: 0.6490\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.62480 to 0.64900, saving model to best_model.h5\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.9225 - accuracy: 0.6719 - val_loss: 0.8785 - val_accuracy: 0.6939\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.64900 to 0.69390, saving model to best_model.h5\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.8209 - accuracy: 0.7093 - val_loss: 0.8070 - val_accuracy: 0.7113\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.69390 to 0.71130, saving model to best_model.h5\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.7461 - accuracy: 0.7371 - val_loss: 0.7473 - val_accuracy: 0.7430\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.71130 to 0.74300, saving model to best_model.h5\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.6964 - accuracy: 0.7534 - val_loss: 0.6972 - val_accuracy: 0.7649\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.74300 to 0.76490, saving model to best_model.h5\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.6431 - accuracy: 0.7753 - val_loss: 0.6917 - val_accuracy: 0.7651\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.76490 to 0.76510, saving model to best_model.h5\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5974 - accuracy: 0.7903 - val_loss: 0.6648 - val_accuracy: 0.7736\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.76510 to 0.77360, saving model to best_model.h5\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5634 - accuracy: 0.8019 - val_loss: 0.6529 - val_accuracy: 0.7780\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.77360 to 0.77800, saving model to best_model.h5\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.5330 - accuracy: 0.8139 - val_loss: 0.6274 - val_accuracy: 0.7817\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.77800 to 0.78170, saving model to best_model.h5\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.4968 - accuracy: 0.8235 - val_loss: 0.6169 - val_accuracy: 0.7900\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.78170 to 0.79000, saving model to best_model.h5\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.4704 - accuracy: 0.8302 - val_loss: 0.6617 - val_accuracy: 0.7749\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.79000\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.4650 - accuracy: 0.8330 - val_loss: 0.6230 - val_accuracy: 0.7853\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.79000\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.4330 - accuracy: 0.8426 - val_loss: 0.6099 - val_accuracy: 0.7945\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.79000 to 0.79450, saving model to best_model.h5\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.4224 - accuracy: 0.8496 - val_loss: 0.6584 - val_accuracy: 0.7833\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.79450\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3958 - accuracy: 0.8595 - val_loss: 0.6160 - val_accuracy: 0.7964\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.79450 to 0.79640, saving model to best_model.h5\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3716 - accuracy: 0.8685 - val_loss: 0.6186 - val_accuracy: 0.7907\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.79640\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.3747 - accuracy: 0.8673 - val_loss: 0.6038 - val_accuracy: 0.8004\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.79640 to 0.80040, saving model to best_model.h5\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.3539 - accuracy: 0.8736 - val_loss: 0.6019 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.80040\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3369 - accuracy: 0.8775 - val_loss: 0.5929 - val_accuracy: 0.8060\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.80040 to 0.80600, saving model to best_model.h5\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3298 - accuracy: 0.8851 - val_loss: 0.5911 - val_accuracy: 0.8110\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.80600 to 0.81100, saving model to best_model.h5\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3239 - accuracy: 0.8837 - val_loss: 0.5890 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.81100 to 0.81280, saving model to best_model.h5\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.3163 - accuracy: 0.8859 - val_loss: 0.6263 - val_accuracy: 0.8032\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.81280\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.3158 - accuracy: 0.8892 - val_loss: 0.5938 - val_accuracy: 0.8047\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.81280\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2907 - accuracy: 0.8963 - val_loss: 0.6286 - val_accuracy: 0.8019\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.81280\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2969 - accuracy: 0.8934 - val_loss: 0.6020 - val_accuracy: 0.8107\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.81280\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2882 - accuracy: 0.8989 - val_loss: 0.5970 - val_accuracy: 0.8118\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.81280\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2777 - accuracy: 0.9015 - val_loss: 0.6462 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.81280\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2786 - accuracy: 0.9022 - val_loss: 0.6500 - val_accuracy: 0.7972\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.81280\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2756 - accuracy: 0.9014 - val_loss: 0.6208 - val_accuracy: 0.8079\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.81280\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2638 - accuracy: 0.9081 - val_loss: 0.6136 - val_accuracy: 0.8051\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.81280\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2516 - accuracy: 0.9129 - val_loss: 0.5978 - val_accuracy: 0.8126\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.81280\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 6s 16ms/step - loss: 0.2537 - accuracy: 0.9124 - val_loss: 0.6068 - val_accuracy: 0.8122\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.81280\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2512 - accuracy: 0.9108 - val_loss: 0.6145 - val_accuracy: 0.8105\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.81280\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2483 - accuracy: 0.9132 - val_loss: 0.6159 - val_accuracy: 0.8119\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.81280\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2435 - accuracy: 0.9134 - val_loss: 0.5896 - val_accuracy: 0.8180\n",
            "\n",
            "Epoch 00038: val_accuracy improved from 0.81280 to 0.81800, saving model to best_model.h5\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2403 - accuracy: 0.9151 - val_loss: 0.6416 - val_accuracy: 0.8044\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.81800\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2424 - accuracy: 0.9131 - val_loss: 0.6178 - val_accuracy: 0.8156\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.81800\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2372 - accuracy: 0.9152 - val_loss: 0.6227 - val_accuracy: 0.8095\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.81800\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2309 - accuracy: 0.9196 - val_loss: 0.6140 - val_accuracy: 0.8172\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.81800\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2325 - accuracy: 0.9184 - val_loss: 0.6009 - val_accuracy: 0.8151\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.81800\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2215 - accuracy: 0.9227 - val_loss: 0.6242 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.81800\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2295 - accuracy: 0.9199 - val_loss: 0.6518 - val_accuracy: 0.8039\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.81800\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.2279 - accuracy: 0.9212 - val_loss: 0.6182 - val_accuracy: 0.8163\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.81800\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.6223 - val_accuracy: 0.8157\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.81800\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2184 - accuracy: 0.9236 - val_loss: 0.6354 - val_accuracy: 0.8066\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.81800\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2234 - accuracy: 0.9214 - val_loss: 0.6565 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.81800\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2344 - accuracy: 0.9212 - val_loss: 0.6368 - val_accuracy: 0.8101\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.81800\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2169 - accuracy: 0.9244 - val_loss: 0.6084 - val_accuracy: 0.8124\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.81800\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2196 - accuracy: 0.9234 - val_loss: 0.6174 - val_accuracy: 0.8147\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.81800\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2139 - accuracy: 0.9255 - val_loss: 0.6249 - val_accuracy: 0.8165\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.81800\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2120 - accuracy: 0.9244 - val_loss: 0.5801 - val_accuracy: 0.8285\n",
            "\n",
            "Epoch 00054: val_accuracy improved from 0.81800 to 0.82850, saving model to best_model.h5\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2124 - accuracy: 0.9267 - val_loss: 0.6357 - val_accuracy: 0.8105\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.82850\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2188 - accuracy: 0.9244 - val_loss: 0.6162 - val_accuracy: 0.8144\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.82850\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2080 - accuracy: 0.9274 - val_loss: 0.6257 - val_accuracy: 0.8177\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.82850\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.2002 - accuracy: 0.9327 - val_loss: 0.5775 - val_accuracy: 0.8210\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.82850\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1951 - accuracy: 0.9318 - val_loss: 0.6303 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.82850\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2121 - accuracy: 0.9275 - val_loss: 0.6049 - val_accuracy: 0.8205\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.82850\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2072 - accuracy: 0.9307 - val_loss: 0.6113 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.82850\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.2040 - accuracy: 0.9293 - val_loss: 0.6171 - val_accuracy: 0.8191\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.82850\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1944 - accuracy: 0.9335 - val_loss: 0.6044 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.82850\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1957 - accuracy: 0.9334 - val_loss: 0.6287 - val_accuracy: 0.8113\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.82850\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1999 - accuracy: 0.9333 - val_loss: 0.6249 - val_accuracy: 0.8167\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.82850\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1976 - accuracy: 0.9320 - val_loss: 0.5981 - val_accuracy: 0.8204\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.82850\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1938 - accuracy: 0.9323 - val_loss: 0.6063 - val_accuracy: 0.8246\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.82850\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1966 - accuracy: 0.9320 - val_loss: 0.6092 - val_accuracy: 0.8161\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.82850\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1927 - accuracy: 0.9319 - val_loss: 0.6348 - val_accuracy: 0.8175\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.82850\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1912 - accuracy: 0.9350 - val_loss: 0.6253 - val_accuracy: 0.8145\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.82850\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1899 - accuracy: 0.9348 - val_loss: 0.6227 - val_accuracy: 0.8156\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.82850\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1892 - accuracy: 0.9338 - val_loss: 0.6214 - val_accuracy: 0.8202\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.82850\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1913 - accuracy: 0.9337 - val_loss: 0.6294 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.82850\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1996 - accuracy: 0.9324 - val_loss: 0.6602 - val_accuracy: 0.8085\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.82850\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1953 - accuracy: 0.9333 - val_loss: 0.6217 - val_accuracy: 0.8228\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.82850\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1960 - accuracy: 0.9345 - val_loss: 0.6170 - val_accuracy: 0.8198\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.82850\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1864 - accuracy: 0.9369 - val_loss: 0.5998 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.82850\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1911 - accuracy: 0.9344 - val_loss: 0.6402 - val_accuracy: 0.8093\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.82850\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1930 - accuracy: 0.9339 - val_loss: 0.6207 - val_accuracy: 0.8174\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.82850\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1827 - accuracy: 0.9370 - val_loss: 0.6445 - val_accuracy: 0.8186\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.82850\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1889 - accuracy: 0.9361 - val_loss: 0.6148 - val_accuracy: 0.8188\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.82850\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1901 - accuracy: 0.9363 - val_loss: 0.6306 - val_accuracy: 0.8172\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.82850\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1785 - accuracy: 0.9386 - val_loss: 0.5864 - val_accuracy: 0.8267\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.82850\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1871 - accuracy: 0.9378 - val_loss: 0.6359 - val_accuracy: 0.8132\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.82850\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1939 - accuracy: 0.9343 - val_loss: 0.6068 - val_accuracy: 0.8221\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.82850\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1755 - accuracy: 0.9388 - val_loss: 0.6641 - val_accuracy: 0.8121\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.82850\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1978 - accuracy: 0.9339 - val_loss: 0.6043 - val_accuracy: 0.8226\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.82850\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1848 - accuracy: 0.9383 - val_loss: 0.6243 - val_accuracy: 0.8219\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.82850\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1859 - accuracy: 0.9346 - val_loss: 0.6127 - val_accuracy: 0.8208\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.82850\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1876 - accuracy: 0.9375 - val_loss: 0.5982 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.82850\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 6s 17ms/step - loss: 0.1858 - accuracy: 0.9373 - val_loss: 0.6246 - val_accuracy: 0.8199\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.82850\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1754 - accuracy: 0.9413 - val_loss: 0.6096 - val_accuracy: 0.8231\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.82850\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1763 - accuracy: 0.9409 - val_loss: 0.6175 - val_accuracy: 0.8152\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.82850\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1841 - accuracy: 0.9389 - val_loss: 0.6458 - val_accuracy: 0.8109\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.82850\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1730 - accuracy: 0.9412 - val_loss: 0.6239 - val_accuracy: 0.8193\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.82850\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1828 - accuracy: 0.9368 - val_loss: 0.6117 - val_accuracy: 0.8196\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.82850\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 7s 18ms/step - loss: 0.1798 - accuracy: 0.9392 - val_loss: 0.5923 - val_accuracy: 0.8243\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.82850\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1822 - accuracy: 0.9393 - val_loss: 0.6161 - val_accuracy: 0.8195\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.82850\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1757 - accuracy: 0.9415 - val_loss: 0.6081 - val_accuracy: 0.8197\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.82850\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 7s 17ms/step - loss: 0.1932 - accuracy: 0.9353 - val_loss: 0.6175 - val_accuracy: 0.8197\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.82850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3550208d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRxEQ6g4wQni"
      },
      "source": [
        "# load the saved model\n",
        "saved_model = load_model('best_model.h5')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BesdlfuC04Qf"
      },
      "source": [
        "## Final Model evaluation with the use of callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4EX-PXpwSWn",
        "outputId": "d9f4fc9a-c035-477e-e9fd-ce266647af00"
      },
      "source": [
        "# evaluate the model\n",
        "_, train_acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = saved_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print('Training Accuracy: %.3f, Testing Accuracy: %.3f' % (train_acc*100, test_acc*100))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 99.272, Testing Accuracy: 81.970\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}