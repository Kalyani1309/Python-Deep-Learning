{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction with deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "ApzFGDkOHnt7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reads .csv file \n",
    "dataset = pd.read_csv(\"C:/Users/nikur/OneDrive/Desktop/01 Python and Deep Learning Programming/Assignment 4/Part 2/Breas Cancer.csv\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,2:32].values\n",
    "y = dataset.iloc[:,1].values\n",
    "\n",
    "# Trnasform y data by labelEncoder as it is a categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Test and train data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (426, 30)\n",
      "Y_train.shape:  (426,)\n",
      "X_test.shape:  (143, 30)\n",
      "Y_test.shape:  (143,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"Y_train.shape: \", Y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"Y_test.shape: \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply existing model provided in the usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "rMfomxTmH3ww"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 8.3488 - acc: 0.3683\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 3.6490 - acc: 0.3610\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 996us/step - loss: 2.0708 - acc: 0.3707\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.4415 - acc: 0.5141\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.9708 - acc: 0.6231\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7313 - acc: 0.6909\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 998us/step - loss: 0.5963 - acc: 0.7831\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5561 - acc: 0.8292\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4656 - acc: 0.8350\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4467 - acc: 0.8731\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4553 - acc: 0.8706\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3492 - acc: 0.9056\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3771 - acc: 0.8694\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3736 - acc: 0.8691\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4078 - acc: 0.8520\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3214 - acc: 0.8958\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3341 - acc: 0.8822\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4178 - acc: 0.8697\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3345 - acc: 0.8908\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3122 - acc: 0.8972\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2973 - acc: 0.8760\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3214 - acc: 0.8866\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2982 - acc: 0.9100\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3034 - acc: 0.8754\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2974 - acc: 0.8941\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2821 - acc: 0.9020\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3248 - acc: 0.8725\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4471 - acc: 0.8765\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.8733\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2998 - acc: 0.8918\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2079 - acc: 0.9164\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3126 - acc: 0.8950\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3560 - acc: 0.8803\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5199 - acc: 0.8412\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3380 - acc: 0.8833\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2625 - acc: 0.8972\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.9056\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2207 - acc: 0.9217\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2610 - acc: 0.9012\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2069 - acc: 0.9232\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2205 - acc: 0.9162\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2790 - acc: 0.9108\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2315 - acc: 0.9141\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2617 - acc: 0.9207\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3430 - acc: 0.8886\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3565 - acc: 0.8726\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1918 - acc: 0.9296\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2324 - acc: 0.9177\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2624 - acc: 0.9108\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1889 - acc: 0.9344\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1828 - acc: 0.9228\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1984 - acc: 0.9203\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2352 - acc: 0.9239\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2865 - acc: 0.9016\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1997 - acc: 0.9120\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2527 - acc: 0.8963\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2519 - acc: 0.9124\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.2240 - acc: 0.9158\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.2509 - acc: 0.9058\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.1976 - acc: 0.9306\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2082 - acc: 0.9316\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2618 - acc: 0.8977\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1980 - acc: 0.9216\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2309 - acc: 0.9180\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1911 - acc: 0.9196\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1919 - acc: 0.9278\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1942 - acc: 0.9302\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2166 - acc: 0.9235\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2032 - acc: 0.9191\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1729 - acc: 0.9382\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2000 - acc: 0.9323\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2585 - acc: 0.8909\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2761 - acc: 0.8989\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2872 - acc: 0.843 - 0s 920us/step - loss: 0.2098 - acc: 0.9007\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.2329 - acc: 0.9095\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2231 - acc: 0.9221\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.1795 - acc: 0.9419\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.1634 - acc: 0.9281\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.2329 - acc: 0.8971\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1714 - acc: 0.9484\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 920us/step - loss: 0.2013 - acc: 0.9094\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2037 - acc: 0.9155\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1725 - acc: 0.9345\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 768us/step - loss: 0.2508 - acc: 0.9072\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.1686 - acc: 0.9261\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 807us/step - loss: 0.2701 - acc: 0.9001\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 867us/step - loss: 0.3045 - acc: 0.8777\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 779us/step - loss: 0.2565 - acc: 0.9030\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2424 - acc: 0.9143\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 868us/step - loss: 0.2119 - acc: 0.9330\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2937 - acc: 0.875 - 0s 922us/step - loss: 0.2200 - acc: 0.9057\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1789 - acc: 0.9269\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 771us/step - loss: 0.2575 - acc: 0.8991\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 752us/step - loss: 0.1863 - acc: 0.9185\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 807us/step - loss: 0.1444 - acc: 0.9496\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 879us/step - loss: 0.2056 - acc: 0.9143\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 919us/step - loss: 0.1918 - acc: 0.9347\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 768us/step - loss: 0.1749 - acc: 0.9263\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 688us/step - loss: 0.3036 - acc: 0.8926\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 786us/step - loss: 0.1906 - acc: 0.9254\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 949us/step - loss: 0.2695 - acc: 0.9157\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.2142 - acc: 0.9160\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3133 - acc: 0.9023\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 935us/step - loss: 0.1621 - acc: 0.9334\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1407 - acc: 0.9504\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 614us/step - loss: 0.1436 - acc: 0.9469\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1345 - acc: 0.9389\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 772us/step - loss: 0.3550 - acc: 0.8772\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 865us/step - loss: 0.4615 - acc: 0.8765\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2299 - acc: 0.9254\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.1807 - acc: 0.9322\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1948 - acc: 0.9321\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.1586 - acc: 0.9283\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 766us/step - loss: 0.1654 - acc: 0.9426\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 964us/step - loss: 0.1627 - acc: 0.9260\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 931us/step - loss: 0.1500 - acc: 0.9470\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 842us/step - loss: 0.1274 - acc: 0.9354\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.1672 - acc: 0.9336\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 784us/step - loss: 0.1935 - acc: 0.9081\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 852us/step - loss: 0.1666 - acc: 0.9268\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 907us/step - loss: 0.1368 - acc: 0.9382\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1178 - acc: 0.9491\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1165 - acc: 0.9555\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 691us/step - loss: 0.2025 - acc: 0.9145\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 691us/step - loss: 0.1553 - acc: 0.9399\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 910us/step - loss: 0.1860 - acc: 0.9159\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1565 - acc: 0.9303\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 799us/step - loss: 0.1736 - acc: 0.9435\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1319 - acc: 0.9427\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 732us/step - loss: 0.2078 - acc: 0.9211\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 716us/step - loss: 0.2991 - acc: 0.8840\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 857us/step - loss: 0.1755 - acc: 0.9220\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1391 - acc: 0.9390\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1257 - acc: 0.9423\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 878us/step - loss: 0.2062 - acc: 0.9230\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 852us/step - loss: 0.1341 - acc: 0.9455\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 823us/step - loss: 0.1451 - acc: 0.9444\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1522 - acc: 0.9290\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 897us/step - loss: 0.1909 - acc: 0.9187\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 919us/step - loss: 0.1666 - acc: 0.9321\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 919us/step - loss: 0.1316 - acc: 0.9488\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 923us/step - loss: 0.1775 - acc: 0.9441\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 989us/step - loss: 0.1503 - acc: 0.9303\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 830us/step - loss: 0.1800 - acc: 0.9132\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 775us/step - loss: 0.2196 - acc: 0.9211\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 946us/step - loss: 0.3620 - acc: 0.8676\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 912us/step - loss: 0.2369 - acc: 0.9220\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 890us/step - loss: 0.1835 - acc: 0.9207\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 843us/step - loss: 0.1400 - acc: 0.9322\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 865us/step - loss: 0.1729 - acc: 0.9284\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 693us/step - loss: 0.1880 - acc: 0.9190\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 824us/step - loss: 0.1901 - acc: 0.9416\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 909us/step - loss: 0.1542 - acc: 0.9517\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 955us/step - loss: 0.1259 - acc: 0.9455\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 872us/step - loss: 0.1600 - acc: 0.9390\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.1584 - acc: 0.9339\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 853us/step - loss: 0.0950 - acc: 0.9650\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 955us/step - loss: 0.1709 - acc: 0.9230\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 916us/step - loss: 0.1384 - acc: 0.9425\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 842us/step - loss: 0.1162 - acc: 0.9516\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 923us/step - loss: 0.1382 - acc: 0.9397\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 886us/step - loss: 0.0851 - acc: 0.9711\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 960us/step - loss: 0.1209 - acc: 0.9404\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 923us/step - loss: 0.1452 - acc: 0.9432\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 845us/step - loss: 0.1949 - acc: 0.9283\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 750us/step - loss: 0.1080 - acc: 0.9585\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 756us/step - loss: 0.1244 - acc: 0.9437\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 890us/step - loss: 0.1187 - acc: 0.9478\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 909us/step - loss: 0.1507 - acc: 0.9377\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2932 - acc: 0.9181\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.1203 - acc: 0.9565\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 691us/step - loss: 0.1110 - acc: 0.9618\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 756us/step - loss: 0.1324 - acc: 0.9502\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 993us/step - loss: 0.2559 - acc: 0.9046\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 891us/step - loss: 0.1546 - acc: 0.9470\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.1312 - acc: 0.9382\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 830us/step - loss: 0.1238 - acc: 0.9440\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 817us/step - loss: 0.1298 - acc: 0.9494\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 692us/step - loss: 0.1907 - acc: 0.9341\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 732us/step - loss: 0.1859 - acc: 0.9348\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 896us/step - loss: 0.2038 - acc: 0.9293\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 990us/step - loss: 0.3065 - acc: 0.8912\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 914us/step - loss: 0.1313 - acc: 0.9493\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.1499 - acc: 0.9386\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 760us/step - loss: 0.1650 - acc: 0.9105\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 795us/step - loss: 0.1322 - acc: 0.9426\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 935us/step - loss: 0.2055 - acc: 0.9305\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 901us/step - loss: 0.1063 - acc: 0.9585\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.2275 - acc: 0.9197\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 833us/step - loss: 0.1363 - acc: 0.9532\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.1733 - acc: 0.9334\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 870us/step - loss: 0.1235 - acc: 0.9536\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 974us/step - loss: 0.1269 - acc: 0.9353\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 948us/step - loss: 0.1460 - acc: 0.9379\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 938us/step - loss: 0.1724 - acc: 0.9344\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 835us/step - loss: 0.1223 - acc: 0.9376\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.1453 - acc: 0.9386\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 852us/step - loss: 0.1115 - acc: 0.9546\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 875us/step - loss: 0.1356 - acc: 0.9538\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 873us/step - loss: 0.1313 - acc: 0.9439\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential() # create a Sequential model\n",
    "\n",
    "model1.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
    "model1.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# The returned history object holds a record of the loss values and metric values during training\n",
    "history =  model1_fitted = model1.fit(X_train, Y_train, epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "id": "19SYVY4DH7OW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 1 Accuracy:  0.9370629191398621\n",
      "Model 1 Loss:  0.16163232922554016\n"
     ]
    }
   ],
   "source": [
    "print(model1.summary())\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 1 Accuracy: \", accuracy)\n",
    "print(\"Model 1 Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more Dense layers to the existing code and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential() # create a Sequential model\n",
    "\n",
    "model2.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
    "\n",
    "# Add more Dense layers to the existing code\n",
    "model2.add(Dense(30, activation='relu')) \n",
    "\n",
    "model2.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the validation_data=(X_test, Y_test) attribute to .fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 16ms/step - loss: 6.2635 - acc: 0.3589 - val_loss: 3.5110 - val_acc: 0.6084\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 3.4415 - acc: 0.5162 - val_loss: 1.3356 - val_acc: 0.5105\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1485 - acc: 0.5205 - val_loss: 0.7155 - val_acc: 0.6014\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5892 - acc: 0.7715 - val_loss: 0.4978 - val_acc: 0.8112\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4525 - acc: 0.8426 - val_loss: 0.4094 - val_acc: 0.8531\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.8491 - val_loss: 0.3090 - val_acc: 0.8951\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3460 - acc: 0.8466 - val_loss: 0.3863 - val_acc: 0.8322\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3256 - acc: 0.8777 - val_loss: 0.5483 - val_acc: 0.7273\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3780 - acc: 0.8331 - val_loss: 0.4434 - val_acc: 0.8112\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3476 - acc: 0.8635 - val_loss: 0.2568 - val_acc: 0.9091\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2152 - acc: 0.9152 - val_loss: 0.2512 - val_acc: 0.9091\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2308 - acc: 0.9034 - val_loss: 0.2379 - val_acc: 0.9021\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2141 - acc: 0.9259 - val_loss: 0.2305 - val_acc: 0.9161\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2346 - acc: 0.8997 - val_loss: 0.2217 - val_acc: 0.9091\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2303 - acc: 0.9036 - val_loss: 0.2175 - val_acc: 0.9161\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2022 - acc: 0.9154 - val_loss: 0.2344 - val_acc: 0.9021\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2202 - acc: 0.9142 - val_loss: 0.2736 - val_acc: 0.8951\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2246 - acc: 0.9031 - val_loss: 0.2374 - val_acc: 0.9091\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2210 - acc: 0.9111 - val_loss: 0.2333 - val_acc: 0.9091\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2304 - acc: 0.8959 - val_loss: 0.2342 - val_acc: 0.9091\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1873 - acc: 0.9135 - val_loss: 0.2483 - val_acc: 0.9021\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2174 - acc: 0.9051 - val_loss: 0.2492 - val_acc: 0.9021\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2525 - acc: 0.9100 - val_loss: 0.2833 - val_acc: 0.8951\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2831 - acc: 0.9007 - val_loss: 0.2096 - val_acc: 0.9021\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1979 - acc: 0.9205 - val_loss: 0.2252 - val_acc: 0.9021\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1683 - acc: 0.9316 - val_loss: 0.1981 - val_acc: 0.9231\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1742 - acc: 0.9237 - val_loss: 0.1948 - val_acc: 0.9371\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1792 - acc: 0.9318 - val_loss: 0.2510 - val_acc: 0.9021\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2383 - acc: 0.9086 - val_loss: 0.2030 - val_acc: 0.9231\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2491 - acc: 0.8942 - val_loss: 0.2040 - val_acc: 0.9231\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3323 - acc: 0.8899 - val_loss: 0.2067 - val_acc: 0.9091\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2381 - acc: 0.9103 - val_loss: 0.4584 - val_acc: 0.7832\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3484 - acc: 0.8626 - val_loss: 0.1934 - val_acc: 0.9301\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1944 - acc: 0.9231 - val_loss: 0.2315 - val_acc: 0.9021\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2017 - acc: 0.9280 - val_loss: 0.2934 - val_acc: 0.8951\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2293 - acc: 0.9138 - val_loss: 0.2006 - val_acc: 0.9231\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1948 - acc: 0.9145 - val_loss: 0.2082 - val_acc: 0.9231\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1736 - acc: 0.9296 - val_loss: 0.1922 - val_acc: 0.9231\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1739 - acc: 0.9357 - val_loss: 0.1920 - val_acc: 0.9161\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1680 - acc: 0.9326 - val_loss: 0.2404 - val_acc: 0.9021\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2047 - acc: 0.9158 - val_loss: 0.2094 - val_acc: 0.9091\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2578 - acc: 0.8862 - val_loss: 0.1864 - val_acc: 0.9441\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1937 - acc: 0.9178 - val_loss: 0.2273 - val_acc: 0.9161\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2143 - acc: 0.9191 - val_loss: 0.1979 - val_acc: 0.9161\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2022 - acc: 0.9240 - val_loss: 0.2062 - val_acc: 0.9091\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1903 - acc: 0.9078 - val_loss: 0.1904 - val_acc: 0.9301\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1824 - acc: 0.9265 - val_loss: 0.3269 - val_acc: 0.8881\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2671 - acc: 0.9104 - val_loss: 0.6312 - val_acc: 0.7552\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5651 - acc: 0.7881 - val_loss: 0.7529 - val_acc: 0.8252\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4531 - acc: 0.8638 - val_loss: 0.2241 - val_acc: 0.9091\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2176 - acc: 0.9174 - val_loss: 0.2571 - val_acc: 0.8951\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1964 - acc: 0.9249 - val_loss: 0.2230 - val_acc: 0.9161\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1713 - acc: 0.9314 - val_loss: 0.1878 - val_acc: 0.9231\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1882 - acc: 0.9267 - val_loss: 0.1888 - val_acc: 0.9301\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1660 - acc: 0.9286 - val_loss: 0.2067 - val_acc: 0.9231\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2038 - acc: 0.9178 - val_loss: 0.2002 - val_acc: 0.9161\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2042 - acc: 0.9398 - val_loss: 0.1883 - val_acc: 0.9301\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1866 - acc: 0.9223 - val_loss: 0.2174 - val_acc: 0.9231\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1866 - acc: 0.9210 - val_loss: 0.2584 - val_acc: 0.8951\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1636 - acc: 0.9354 - val_loss: 0.1854 - val_acc: 0.9231\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2142 - acc: 0.9137 - val_loss: 0.1932 - val_acc: 0.9161\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2030 - acc: 0.9057 - val_loss: 0.2780 - val_acc: 0.8951\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3986 - acc: 0.8845 - val_loss: 0.1931 - val_acc: 0.9231\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3086 - acc: 0.8908 - val_loss: 0.4853 - val_acc: 0.7832\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2496 - acc: 0.8968 - val_loss: 0.2620 - val_acc: 0.8951\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2398 - acc: 0.9154 - val_loss: 0.1955 - val_acc: 0.9231\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1728 - acc: 0.9422 - val_loss: 0.2043 - val_acc: 0.9231\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1590 - acc: 0.9280 - val_loss: 0.2194 - val_acc: 0.9231\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2389 - acc: 0.9234 - val_loss: 0.1840 - val_acc: 0.9231\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2210 - acc: 0.9142 - val_loss: 0.3690 - val_acc: 0.8531\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2254 - acc: 0.9197 - val_loss: 0.2564 - val_acc: 0.9021\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2118 - acc: 0.9283 - val_loss: 0.1985 - val_acc: 0.9301\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1616 - acc: 0.9315 - val_loss: 0.1953 - val_acc: 0.9161\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9351 - val_loss: 0.2122 - val_acc: 0.9161\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1529 - acc: 0.9340 - val_loss: 0.1874 - val_acc: 0.9301\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1600 - acc: 0.9374 - val_loss: 0.1939 - val_acc: 0.9161\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1453 - acc: 0.9438 - val_loss: 0.1854 - val_acc: 0.9301\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1982 - acc: 0.9179 - val_loss: 0.2011 - val_acc: 0.9161\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1891 - acc: 0.9297 - val_loss: 0.3193 - val_acc: 0.8951\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2902 - acc: 0.9154 - val_loss: 0.2470 - val_acc: 0.8951\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2212 - acc: 0.9211 - val_loss: 0.1850 - val_acc: 0.9301\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1961 - acc: 0.9169 - val_loss: 0.1867 - val_acc: 0.9231\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1916 - acc: 0.9104 - val_loss: 0.2725 - val_acc: 0.8881\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2795 - acc: 0.8860 - val_loss: 0.2375 - val_acc: 0.8951\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1649 - acc: 0.9291 - val_loss: 0.1837 - val_acc: 0.9301\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1419 - acc: 0.9312 - val_loss: 0.1901 - val_acc: 0.9161\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1616 - acc: 0.9400 - val_loss: 0.1821 - val_acc: 0.9301\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1593 - acc: 0.9438 - val_loss: 0.2724 - val_acc: 0.8951\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2092 - acc: 0.9256 - val_loss: 0.2410 - val_acc: 0.8951\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1823 - acc: 0.9417 - val_loss: 0.2500 - val_acc: 0.8951\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1601 - acc: 0.9363 - val_loss: 0.1990 - val_acc: 0.9231\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1764 - acc: 0.9092 - val_loss: 0.1841 - val_acc: 0.9231\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1583 - acc: 0.9341 - val_loss: 0.1882 - val_acc: 0.9161\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1535 - acc: 0.9298 - val_loss: 0.2027 - val_acc: 0.9161\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1251 - acc: 0.9508 - val_loss: 0.1859 - val_acc: 0.9161\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1815 - acc: 0.9332 - val_loss: 0.2957 - val_acc: 0.8811\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2164 - acc: 0.9084 - val_loss: 0.3205 - val_acc: 0.8951\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2791 - acc: 0.9156 - val_loss: 0.3716 - val_acc: 0.8462\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3710 - acc: 0.8956 - val_loss: 0.5987 - val_acc: 0.8601\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3109 - acc: 0.9162 - val_loss: 0.1793 - val_acc: 0.9231\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1823 - acc: 0.9302 - val_loss: 0.1810 - val_acc: 0.9301\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1681 - acc: 0.9317 - val_loss: 0.1883 - val_acc: 0.9161\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1512 - acc: 0.9487 - val_loss: 0.3426 - val_acc: 0.8951\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2535 - acc: 0.9177 - val_loss: 0.1846 - val_acc: 0.9301\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2068 - acc: 0.9077 - val_loss: 0.2623 - val_acc: 0.8881\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2069 - acc: 0.9043 - val_loss: 0.2968 - val_acc: 0.8741\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1952 - acc: 0.9283 - val_loss: 0.2230 - val_acc: 0.9231\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1506 - acc: 0.9363 - val_loss: 0.3182 - val_acc: 0.8671\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2410 - acc: 0.8997 - val_loss: 0.1809 - val_acc: 0.9301\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1259 - acc: 0.9584 - val_loss: 0.1826 - val_acc: 0.9231\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2022 - acc: 0.9164 - val_loss: 0.2728 - val_acc: 0.9021\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1257 - acc: 0.9506 - val_loss: 0.1858 - val_acc: 0.9161\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2554 - acc: 0.8924 - val_loss: 0.1817 - val_acc: 0.9231\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1470 - acc: 0.9477 - val_loss: 0.3271 - val_acc: 0.8951\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1421 - acc: 0.9417 - val_loss: 0.1824 - val_acc: 0.9301\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1607 - acc: 0.9313 - val_loss: 0.1944 - val_acc: 0.9161\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1971 - acc: 0.9234 - val_loss: 0.4744 - val_acc: 0.8042\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3385 - acc: 0.8731 - val_loss: 0.2244 - val_acc: 0.9231\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1599 - acc: 0.9388 - val_loss: 0.1819 - val_acc: 0.9231\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1781 - acc: 0.9169 - val_loss: 0.2296 - val_acc: 0.9021\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2656 - acc: 0.9243 - val_loss: 0.2544 - val_acc: 0.8881\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1870 - acc: 0.9088 - val_loss: 0.2115 - val_acc: 0.9161\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1447 - acc: 0.9410 - val_loss: 0.1834 - val_acc: 0.9231\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1532 - acc: 0.9422 - val_loss: 0.2616 - val_acc: 0.9021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1512 - acc: 0.9375 - val_loss: 0.2190 - val_acc: 0.9231\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1564 - acc: 0.9409 - val_loss: 0.1988 - val_acc: 0.9231\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1623 - acc: 0.9425 - val_loss: 0.1924 - val_acc: 0.9231\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1399 - acc: 0.9420 - val_loss: 0.2119 - val_acc: 0.9161\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1788 - acc: 0.9257 - val_loss: 0.1811 - val_acc: 0.9301\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1592 - acc: 0.9267 - val_loss: 0.1859 - val_acc: 0.9161\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1910 - acc: 0.9172 - val_loss: 0.1770 - val_acc: 0.9231\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1555 - acc: 0.9326 - val_loss: 0.1804 - val_acc: 0.9231\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1707 - acc: 0.9458 - val_loss: 0.1833 - val_acc: 0.9371\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - acc: 0.9459 - val_loss: 0.2494 - val_acc: 0.8881\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1870 - acc: 0.9331 - val_loss: 0.1808 - val_acc: 0.9301\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9123 - val_loss: 0.2532 - val_acc: 0.9021\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1356 - acc: 0.9420 - val_loss: 0.1759 - val_acc: 0.9231\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2371 - acc: 0.9012 - val_loss: 0.2478 - val_acc: 0.9021\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2088 - acc: 0.9179 - val_loss: 0.2465 - val_acc: 0.8881\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2039 - acc: 0.9314 - val_loss: 0.2191 - val_acc: 0.9231\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2079 - acc: 0.9167 - val_loss: 0.1749 - val_acc: 0.9231\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9340 - val_loss: 0.1783 - val_acc: 0.9231\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1227 - acc: 0.9544 - val_loss: 0.1919 - val_acc: 0.9161\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1645 - acc: 0.9247 - val_loss: 0.2186 - val_acc: 0.9301\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1363 - acc: 0.9482 - val_loss: 0.1924 - val_acc: 0.9161\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1759 - acc: 0.9210 - val_loss: 0.1743 - val_acc: 0.9301\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1455 - acc: 0.9415 - val_loss: 0.2123 - val_acc: 0.9231\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1527 - acc: 0.9392 - val_loss: 0.2125 - val_acc: 0.9091\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1729 - acc: 0.9402 - val_loss: 0.1842 - val_acc: 0.9161\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1738 - acc: 0.9331 - val_loss: 0.1931 - val_acc: 0.9231\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2421 - acc: 0.9268 - val_loss: 0.1862 - val_acc: 0.9161\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1084 - acc: 0.9554 - val_loss: 0.2687 - val_acc: 0.9021\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1346 - acc: 0.9393 - val_loss: 0.3532 - val_acc: 0.8951\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1490 - acc: 0.9300 - val_loss: 0.1779 - val_acc: 0.9231\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1353 - acc: 0.9408 - val_loss: 0.2227 - val_acc: 0.8951\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2392 - acc: 0.9129 - val_loss: 0.1754 - val_acc: 0.9231\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1244 - acc: 0.9439 - val_loss: 0.2053 - val_acc: 0.9231\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1310 - acc: 0.9425 - val_loss: 0.1971 - val_acc: 0.9231\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1671 - acc: 0.9324 - val_loss: 0.2023 - val_acc: 0.9231\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1499 - acc: 0.9400 - val_loss: 0.3081 - val_acc: 0.8671\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1778 - acc: 0.9340 - val_loss: 0.1885 - val_acc: 0.9161\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1315 - acc: 0.9539 - val_loss: 0.1741 - val_acc: 0.9301\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1144 - acc: 0.9533 - val_loss: 0.1695 - val_acc: 0.9301\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1279 - acc: 0.9582 - val_loss: 0.1690 - val_acc: 0.9301\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2075 - acc: 0.9009 - val_loss: 0.1912 - val_acc: 0.9231\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1293 - acc: 0.9421 - val_loss: 0.2346 - val_acc: 0.9231\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2930 - acc: 0.8948 - val_loss: 0.3545 - val_acc: 0.8881\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2029 - acc: 0.9322 - val_loss: 0.1913 - val_acc: 0.9161\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1863 - acc: 0.9225 - val_loss: 0.3220 - val_acc: 0.8951\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2126 - acc: 0.9346 - val_loss: 0.1885 - val_acc: 0.9161\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1880 - acc: 0.9238 - val_loss: 0.2433 - val_acc: 0.9301\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1708 - acc: 0.9367 - val_loss: 0.1722 - val_acc: 0.9161\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1572 - acc: 0.9294 - val_loss: 0.2089 - val_acc: 0.9231\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1454 - acc: 0.9434 - val_loss: 0.1825 - val_acc: 0.9161\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1404 - acc: 0.9279 - val_loss: 0.2019 - val_acc: 0.9231\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1081 - acc: 0.9553 - val_loss: 0.1958 - val_acc: 0.9231\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1226 - acc: 0.9438 - val_loss: 0.1646 - val_acc: 0.9301\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1610 - acc: 0.9182 - val_loss: 0.2185 - val_acc: 0.9301\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1375 - acc: 0.9445 - val_loss: 0.2084 - val_acc: 0.9301\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1067 - acc: 0.9524 - val_loss: 0.1751 - val_acc: 0.9161\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1566 - acc: 0.9222 - val_loss: 0.1655 - val_acc: 0.9301\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2034 - acc: 0.9184 - val_loss: 0.1670 - val_acc: 0.9231\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1883 - acc: 0.9347 - val_loss: 0.1870 - val_acc: 0.9161\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1337 - acc: 0.9300 - val_loss: 0.2015 - val_acc: 0.9231\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1411 - acc: 0.9431 - val_loss: 0.2240 - val_acc: 0.9301\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1738 - acc: 0.9272 - val_loss: 0.1655 - val_acc: 0.9231\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1260 - acc: 0.9457 - val_loss: 0.3192 - val_acc: 0.8671\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2773 - acc: 0.8687 - val_loss: 0.1631 - val_acc: 0.9301\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1582 - acc: 0.9350 - val_loss: 0.1638 - val_acc: 0.9301\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1718 - acc: 0.9192 - val_loss: 0.3485 - val_acc: 0.8601\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2435 - acc: 0.9165 - val_loss: 0.2618 - val_acc: 0.9021\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1550 - acc: 0.9246 - val_loss: 0.2524 - val_acc: 0.9021\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1817 - acc: 0.9476 - val_loss: 0.2872 - val_acc: 0.8881\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1902 - acc: 0.9438 - val_loss: 0.3884 - val_acc: 0.8671\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4601 - acc: 0.8716 - val_loss: 0.2077 - val_acc: 0.9231\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1028 - acc: 0.9661 - val_loss: 0.2390 - val_acc: 0.9231\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.9354 - val_loss: 0.2311 - val_acc: 0.9301\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1591 - acc: 0.9345 - val_loss: 0.1729 - val_acc: 0.9371\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1578 - acc: 0.9398 - val_loss: 0.2212 - val_acc: 0.8951\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1499 - acc: 0.9397 - val_loss: 0.1778 - val_acc: 0.9301\n"
     ]
    }
   ],
   "source": [
    "# Add the validation_data=(X_test, Y_test) attribute to .fit() method\n",
    "history = model2_fitted = model2.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the dense model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 2 Accuracy with added dense layers:  0.9300699234008789\n",
      "Model 2 Loss with added dense layers:  0.17782260477542877\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())\n",
    "\n",
    "loss, accuracy = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 2 Accuracy with added dense layers: \", accuracy)\n",
    "print(\"Model 2 Loss with added dense layers: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracy for training and validation in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Plot of Model Accuracy on Train and Validation Datasets')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data before feeding the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential() # create a Sequential model\n",
    "\n",
    "model3.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
    "\n",
    "# Add more Dense layers to the existing code\n",
    "model3.add(Dense(30, activation='relu')) \n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 1ms/step - loss: 0.5878 - acc: 0.7974\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4386 - acc: 0.9511\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3048 - acc: 0.9699\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 995us/step - loss: 0.2282 - acc: 0.9534\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 999us/step - loss: 0.1637 - acc: 0.9536\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 808us/step - loss: 0.1140 - acc: 0.9691\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 843us/step - loss: 0.0949 - acc: 0.9770\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 846us/step - loss: 0.0824 - acc: 0.9776\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 919us/step - loss: 0.0740 - acc: 0.9791\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0705 - acc: 0.9862\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0519 - acc: 0.9816\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0566 - acc: 0.9909\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 994us/step - loss: 0.0407 - acc: 0.9963\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0342 - acc: 0.9985\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0321 - acc: 0.9985\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 846us/step - loss: 0.0301 - acc: 0.9978\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0278 - acc: 0.9978\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 998us/step - loss: 0.0323 - acc: 0.9931\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 889us/step - loss: 0.0215 - acc: 0.9987\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 923us/step - loss: 0.0227 - acc: 0.9987\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0141 - acc: 0.9994\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0218 - acc: 0.9974\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0240 - acc: 0.9931\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0228 - acc: 0.9931\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 0.9962\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0121 - acc: 0.9992\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0114 - acc: 0.9987\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0142 - acc: 0.9974\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0180 - acc: 0.9951\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0147 - acc: 0.9951\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0099 - acc: 0.9995\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0083 - acc: 0.9990\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.0083 - acc: 0.9995\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.0087 - acc: 0.9982\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0103 - acc: 0.9951\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 920us/step - loss: 0.0078 - acc: 0.9978\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0077 - acc: 0.9985\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 888us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 983us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 842us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 827us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 999us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 928us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 831us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 927us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 864us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 965us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 904us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 852us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 853us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 936us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 983us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 880us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 924us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 769us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 932us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 896us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 908us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 892us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 952us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 970us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 802us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 826us/step - loss: 8.8118e-04 - acc: 1.0000\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 970us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 946us/step - loss: 8.4425e-04 - acc: 1.0000\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 944us/step - loss: 7.7114e-04 - acc: 1.0000\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 966us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 956us/step - loss: 8.6683e-04 - acc: 1.0000\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 871us/step - loss: 9.8667e-04 - acc: 1.0000\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 871us/step - loss: 9.6041e-04 - acc: 1.0000\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 793us/step - loss: 7.9441e-04 - acc: 1.0000\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 953us/step - loss: 8.6520e-04 - acc: 1.0000\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 895us/step - loss: 9.1913e-04 - acc: 1.0000\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 7.3533e-04 - acc: 1.0000\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 6.2882e-04 - acc: 1.0000\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 693us/step - loss: 8.1182e-04 - acc: 1.0000\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 683us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 987us/step - loss: 5.7535e-04 - acc: 1.0000\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 864us/step - loss: 8.3832e-04 - acc: 1.0000\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 905us/step - loss: 7.4887e-04 - acc: 1.0000\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 841us/step - loss: 5.4723e-04 - acc: 1.0000\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 808us/step - loss: 5.6832e-04 - acc: 1.0000\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 972us/step - loss: 6.5616e-04 - acc: 1.0000\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 840us/step - loss: 5.5250e-04 - acc: 1.0000\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 908us/step - loss: 5.5223e-04 - acc: 1.0000\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 896us/step - loss: 5.1336e-04 - acc: 1.0000\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 965us/step - loss: 5.9072e-04 - acc: 1.0000\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 731us/step - loss: 4.7862e-04 - acc: 1.0000\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 920us/step - loss: 3.7411e-04 - acc: 1.0000\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.5227e-04 - acc: 1.0000\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 922us/step - loss: 4.0383e-04 - acc: 1.0000\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 970us/step - loss: 6.4222e-04 - acc: 1.0000\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 892us/step - loss: 5.5487e-04 - acc: 1.0000\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 3.8233e-04 - acc: 1.0000\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 831us/step - loss: 3.8621e-04 - acc: 1.0000\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 718us/step - loss: 4.8933e-04 - acc: 1.0000\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 4.3395e-04 - acc: 1.0000\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 956us/step - loss: 5.1308e-04 - acc: 1.0000\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 810us/step - loss: 3.5044e-04 - acc: 1.0000\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 3.7614e-04 - acc: 1.0000\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 950us/step - loss: 5.9865e-04 - acc: 1.0000\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 852us/step - loss: 5.1953e-04 - acc: 1.0000\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 842us/step - loss: 3.6254e-04 - acc: 1.0000\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 758us/step - loss: 2.9741e-04 - acc: 1.0000\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 882us/step - loss: 4.6099e-04 - acc: 1.0000\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 917us/step - loss: 2.9146e-04 - acc: 1.0000\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 801us/step - loss: 3.4191e-04 - acc: 1.0000\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 2.8063e-04 - acc: 1.0000\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 690us/step - loss: 3.6002e-04 - acc: 1.0000\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 802us/step - loss: 3.1401e-04 - acc: 1.0000\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 941us/step - loss: 2.9705e-04 - acc: 1.0000\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 947us/step - loss: 5.2571e-04 - acc: 1.0000\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 886us/step - loss: 3.3152e-04 - acc: 1.0000\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 876us/step - loss: 3.2001e-04 - acc: 1.0000\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 764us/step - loss: 3.6675e-04 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 807us/step - loss: 4.5918e-04 - acc: 1.0000\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 924us/step - loss: 4.2176e-04 - acc: 1.0000\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 919us/step - loss: 2.6016e-04 - acc: 1.0000\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 918us/step - loss: 3.1909e-04 - acc: 1.0000\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 779us/step - loss: 2.7480e-04 - acc: 1.0000\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 762us/step - loss: 4.5938e-04 - acc: 1.0000\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 874us/step - loss: 4.2156e-04 - acc: 1.0000\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 847us/step - loss: 3.0189e-04 - acc: 1.0000\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 921us/step - loss: 2.5247e-04 - acc: 1.0000\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 908us/step - loss: 2.4079e-04 - acc: 1.0000\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 1.9615e-04 - acc: 1.0000\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 811us/step - loss: 2.3465e-04 - acc: 1.0000\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 843us/step - loss: 2.2360e-04 - acc: 1.0000\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 827us/step - loss: 1.8106e-04 - acc: 1.0000\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 928us/step - loss: 2.2383e-04 - acc: 1.0000\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 843us/step - loss: 2.5780e-04 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 745us/step - loss: 2.4911e-04 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 810us/step - loss: 2.5100e-04 - acc: 1.0000\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 977us/step - loss: 1.7911e-04 - acc: 1.0000\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 970us/step - loss: 2.2428e-04 - acc: 1.0000\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 997us/step - loss: 1.9635e-04 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.9039e-04 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 767us/step - loss: 1.4627e-04 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 716us/step - loss: 2.4563e-04 - acc: 1.0000\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 817us/step - loss: 3.0598e-04 - acc: 1.0000\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 986us/step - loss: 1.6747e-04 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 867us/step - loss: 1.8818e-04 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 1.7391e-04 - acc: 1.0000\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 767us/step - loss: 1.8346e-04 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 759us/step - loss: 1.8871e-04 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 879us/step - loss: 1.7084e-04 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 914us/step - loss: 1.9662e-04 - acc: 1.0000\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 940us/step - loss: 1.7009e-04 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 926us/step - loss: 1.1945e-04 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 799us/step - loss: 1.7750e-04 - acc: 1.0000\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 804us/step - loss: 1.6420e-04 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 875us/step - loss: 1.9062e-04 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 2.1507e-04 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 902us/step - loss: 1.3964e-04 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 790us/step - loss: 1.5263e-04 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 1.3683e-04 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 750us/step - loss: 1.4289e-04 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 752us/step - loss: 1.4912e-04 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 984us/step - loss: 1.3362e-04 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 955us/step - loss: 1.4749e-04 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 1.1898e-04 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 934us/step - loss: 1.7017e-04 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 846us/step - loss: 1.2965e-04 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 797us/step - loss: 1.2728e-04 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 783us/step - loss: 1.0234e-04 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 841us/step - loss: 1.8995e-04 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 868us/step - loss: 1.5671e-04 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 915us/step - loss: 1.1589e-04 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 847us/step - loss: 1.3200e-04 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 759us/step - loss: 1.9283e-04 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 942us/step - loss: 1.6308e-04 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 968us/step - loss: 1.4673e-04 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 6.6660e-05 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 953us/step - loss: 1.4639e-04 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 844us/step - loss: 1.7678e-04 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 747us/step - loss: 8.9764e-05 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 815us/step - loss: 1.2125e-04 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 814us/step - loss: 1.5508e-04 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 918us/step - loss: 9.5779e-05 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# The returned history object holds a record of the loss values and metric values during training\n",
    "model3_fitted = model3.fit(X_train, Y_train, epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the model 3 with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 3 Accuracy after data normalization:  0.9510489702224731\n",
      "Model 3 Loss after data normalization:  0.43767356872558594\n"
     ]
    }
   ],
   "source": [
    "print(model3.summary())\n",
    "\n",
    "loss, accuracy = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 3 Accuracy after data normalization: \", accuracy)\n",
    "print(\"Model 3 Loss after data normalization: \", loss)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Lesson_1_(diabetes).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
