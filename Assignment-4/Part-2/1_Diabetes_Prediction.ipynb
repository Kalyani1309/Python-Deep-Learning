{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTRagYcvHjDj"
   },
   "source": [
    "# Predicting the diabetes disease with deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# load dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "ApzFGDkOHnt7"
   },
   "outputs": [],
   "source": [
    "# Reads .csv file as DataFrame.\n",
    "dataset = pd.read_csv(\"C:/Users/nikur/OneDrive/Desktop/01 Python and Deep Learning Programming/Assignment 4/Part 2/diabetes.csv\", header=None).values # Reads .csv file as Numpy Ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "rHfdZheJ_lh3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "yt64olkkHwft"
   },
   "outputs": [],
   "source": [
    "# Test and train data split\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing model provided in the usecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 878us/step - loss: 11.6874 - acc: 0.5286\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 883us/step - loss: 8.4024 - acc: 0.3344\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 804us/step - loss: 5.8913 - acc: 0.3821\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 716us/step - loss: 5.1893 - acc: 0.4029\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 3.7408 - acc: 0.4373\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 2.8734 - acc: 0.4191\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 852us/step - loss: 1.9697 - acc: 0.4822\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 885us/step - loss: 1.4113 - acc: 0.5071\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 849us/step - loss: 1.1935 - acc: 0.5098\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 939us/step - loss: 1.0825 - acc: 0.5407\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.9278 - acc: 0.6134\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.8706 - acc: 0.6118\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.8324 - acc: 0.6456\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9080 - acc: 0.6332\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.8524 - acc: 0.6083\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.8266 - acc: 0.6719\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.8033 - acc: 0.6273\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.7901 - acc: 0.6442\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.7427 - acc: 0.6471\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.7568 - acc: 0.6668\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.7562 - acc: 0.6513\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.7282 - acc: 0.6542\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.7004 - acc: 0.6680\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.7779 - acc: 0.6334\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.6976 - acc: 0.6773\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.6826 - acc: 0.6767\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.6485 - acc: 0.7004\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.6578 - acc: 0.6978\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.6711 - acc: 0.6903\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.6531 - acc: 0.6872\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.6532 - acc: 0.6739\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.6696 - acc: 0.6707\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.6411 - acc: 0.6868\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6994 - acc: 0.6785\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.7086 - acc: 0.6648\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 806us/step - loss: 0.6729 - acc: 0.6633\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.6182 - acc: 0.7107\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.6039 - acc: 0.7178\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.6608 - acc: 0.7170\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.6302 - acc: 0.6907\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.6383 - acc: 0.7051\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.6262 - acc: 0.6994\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.6180 - acc: 0.6849\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.6775 - acc: 0.6936\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.5938 - acc: 0.7241\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.6153 - acc: 0.7009\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.5539 - acc: 0.7336\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.5954 - acc: 0.6998\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6281 - acc: 0.6791\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5981 - acc: 0.7174\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.5690 - acc: 0.7474\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.5608 - acc: 0.7180\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.6057 - acc: 0.7205\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.5972 - acc: 0.6959\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 809us/step - loss: 0.6111 - acc: 0.6865\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 791us/step - loss: 0.6038 - acc: 0.7221\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 708us/step - loss: 0.5567 - acc: 0.7449\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 645us/step - loss: 0.5975 - acc: 0.7066\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.5634 - acc: 0.7455\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 719us/step - loss: 0.5760 - acc: 0.7309\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 666us/step - loss: 0.5436 - acc: 0.7437\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 782us/step - loss: 0.5481 - acc: 0.7332\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 770us/step - loss: 0.5356 - acc: 0.7294\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 775us/step - loss: 0.5734 - acc: 0.7461\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5440 - acc: 0.7423\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.6320 - acc: 0.6865\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5353 - acc: 0.7443\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 658us/step - loss: 0.6060 - acc: 0.7424\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5335 - acc: 0.7249\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.5770 - acc: 0.7123\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 707us/step - loss: 0.5631 - acc: 0.7448\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.6235 - acc: 0.6947\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 689us/step - loss: 0.5578 - acc: 0.7552\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 687us/step - loss: 0.6371 - acc: 0.7164\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5319 - acc: 0.7598\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 767us/step - loss: 0.5626 - acc: 0.7289\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.5418 - acc: 0.7508\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.5393 - acc: 0.7432\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.5818 - acc: 0.7177\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.5372 - acc: 0.7344\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 775us/step - loss: 0.5559 - acc: 0.7378\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 789us/step - loss: 0.5775 - acc: 0.7564\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.5705 - acc: 0.7112\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.5465 - acc: 0.7594\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 761us/step - loss: 0.5441 - acc: 0.7496\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.5715 - acc: 0.7472\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.5401 - acc: 0.7592\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 816us/step - loss: 0.5203 - acc: 0.7494\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 756us/step - loss: 0.5321 - acc: 0.7458\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.5376 - acc: 0.7362\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.5484 - acc: 0.7400\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 733us/step - loss: 0.5674 - acc: 0.7309\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 722us/step - loss: 0.5595 - acc: 0.7421\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 723us/step - loss: 0.5536 - acc: 0.7424\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 636us/step - loss: 0.5424 - acc: 0.7728\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 591us/step - loss: 0.5622 - acc: 0.7177\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 660us/step - loss: 0.5508 - acc: 0.7277\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 750us/step - loss: 0.5136 - acc: 0.7605\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 814us/step - loss: 0.5177 - acc: 0.7528\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 731us/step - loss: 0.5466 - acc: 0.7440\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 706us/step - loss: 0.5028 - acc: 0.7618\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4338 - acc: 0.843 - 0s 724us/step - loss: 0.4884 - acc: 0.7838\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 737us/step - loss: 0.5314 - acc: 0.7392\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 606us/step - loss: 0.5233 - acc: 0.7591\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5588 - acc: 0.7474\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 796us/step - loss: 0.5251 - acc: 0.7549\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 766us/step - loss: 0.5290 - acc: 0.7667\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 790us/step - loss: 0.5195 - acc: 0.7577\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5841 - acc: 0.7301\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4931 - acc: 0.7602\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 806us/step - loss: 0.5400 - acc: 0.7427\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 793us/step - loss: 0.5499 - acc: 0.7266\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5565 - acc: 0.7540\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 701us/step - loss: 0.5207 - acc: 0.7345\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - acc: 0.7492\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.4992 - acc: 0.7577\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 741us/step - loss: 0.4944 - acc: 0.7694\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 750us/step - loss: 0.5970 - acc: 0.6884\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 802us/step - loss: 0.5311 - acc: 0.7359\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 762us/step - loss: 0.5524 - acc: 0.7490\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 780us/step - loss: 0.5619 - acc: 0.7326\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 779us/step - loss: 0.5049 - acc: 0.7725\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 787us/step - loss: 0.5404 - acc: 0.7526\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 776us/step - loss: 0.4887 - acc: 0.7562\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.5613 - acc: 0.7350\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 705us/step - loss: 0.5303 - acc: 0.7485\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 729us/step - loss: 0.5323 - acc: 0.7628\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5151 - acc: 0.7639\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5097 - acc: 0.7512\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 685us/step - loss: 0.5376 - acc: 0.7702\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 647us/step - loss: 0.5241 - acc: 0.7791\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 639us/step - loss: 0.5576 - acc: 0.7249\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 787us/step - loss: 0.5159 - acc: 0.7583\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 712us/step - loss: 0.5218 - acc: 0.7536\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 689us/step - loss: 0.5240 - acc: 0.7779\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.5507 - acc: 0.7209\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 801us/step - loss: 0.5584 - acc: 0.7428\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 740us/step - loss: 0.5140 - acc: 0.7632\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 647us/step - loss: 0.5183 - acc: 0.7701\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5303 - acc: 0.7332\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4985 - acc: 0.7501\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5087 - acc: 0.7530\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 809us/step - loss: 0.5022 - acc: 0.7507\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.5596 - acc: 0.7473\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 766us/step - loss: 0.5370 - acc: 0.7513\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4921 - acc: 0.7775\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 810us/step - loss: 0.5181 - acc: 0.7734\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.5478 - acc: 0.7353\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 761us/step - loss: 0.5155 - acc: 0.7615\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 753us/step - loss: 0.5076 - acc: 0.7446\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 711us/step - loss: 0.5149 - acc: 0.7272\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 792us/step - loss: 0.4946 - acc: 0.7595\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 687us/step - loss: 0.5259 - acc: 0.7484\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5421 - acc: 0.7097\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 811us/step - loss: 0.6098 - acc: 0.7467\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5063 - acc: 0.7555\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.5442 - acc: 0.7569\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 780us/step - loss: 0.5158 - acc: 0.8008\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.4743 - acc: 0.7989\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.5017 - acc: 0.7530\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5030 - acc: 0.7695\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 800us/step - loss: 0.5373 - acc: 0.7414\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 751us/step - loss: 0.4865 - acc: 0.7867\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 766us/step - loss: 0.5133 - acc: 0.7697\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5112 - acc: 0.7639\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 796us/step - loss: 0.4971 - acc: 0.7501\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.4977 - acc: 0.7803\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 763us/step - loss: 0.5116 - acc: 0.7709\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5353 - acc: 0.7356\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.5072 - acc: 0.7743\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 686us/step - loss: 0.5059 - acc: 0.7722\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 670us/step - loss: 0.5038 - acc: 0.7753\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 599us/step - loss: 0.5033 - acc: 0.7546\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 695us/step - loss: 0.4966 - acc: 0.7657\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 767us/step - loss: 0.5132 - acc: 0.7621\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 767us/step - loss: 0.5364 - acc: 0.7414\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 716us/step - loss: 0.5794 - acc: 0.7259\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 800us/step - loss: 0.5014 - acc: 0.7811\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 728us/step - loss: 0.4889 - acc: 0.7845\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 720us/step - loss: 0.5120 - acc: 0.7799\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 801us/step - loss: 0.4968 - acc: 0.7875\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.4746 - acc: 0.7939\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.4878 - acc: 0.7814\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.5252 - acc: 0.7634\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 762us/step - loss: 0.5255 - acc: 0.7389\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 644us/step - loss: 0.5159 - acc: 0.7536\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 619us/step - loss: 0.5038 - acc: 0.7705\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 686us/step - loss: 0.5031 - acc: 0.7671\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 655us/step - loss: 0.5180 - acc: 0.7685\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4999 - acc: 0.7736\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 745us/step - loss: 0.5346 - acc: 0.7667\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 710us/step - loss: 0.4956 - acc: 0.7914\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 743us/step - loss: 0.5278 - acc: 0.7472\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 681us/step - loss: 0.4946 - acc: 0.7514\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 682us/step - loss: 0.5123 - acc: 0.7558\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 802us/step - loss: 0.5155 - acc: 0.7319\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5059 - acc: 0.7475\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 789us/step - loss: 0.5019 - acc: 0.7631\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.5853 - acc: 0.7309\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.4917 - acc: 0.7743\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential() # create a Sequential model\n",
    "\n",
    "model1.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
    "model1.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# The returned history object holds a record of the loss values and metric values during training\n",
    "model1_fitted = model1.fit(X_train, Y_train, epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 201\n",
      "Trainable params: 201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 1 Accuracy:  0.7135416865348816\n",
      "Model 1 Loss:  0.6174954771995544\n"
     ]
    }
   ],
   "source": [
    "print(model1.summary())\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 1 Accuracy: \", accuracy)\n",
    "print(\"Model 1 Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more Dense layers to the existing code and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "rMfomxTmH3ww"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential() # create a Sequential model\n",
    "\n",
    "model2.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
    "\n",
    "# Add more Dense layers to the existing code\n",
    "model2.add(Dense(30, activation='relu')) \n",
    "\n",
    "model2.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the validation_data=(X_test, Y_test) attribute to .fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 28.2694 - acc: 0.3482 - val_loss: 8.5170 - val_acc: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 4.9012 - acc: 0.4619 - val_loss: 2.7287 - val_acc: 0.6615\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.5662 - acc: 0.5677 - val_loss: 1.4800 - val_acc: 0.5208\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3070 - acc: 0.6127 - val_loss: 1.2279 - val_acc: 0.5885\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1349 - acc: 0.5940 - val_loss: 1.1119 - val_acc: 0.5625\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0282 - acc: 0.5893 - val_loss: 0.9473 - val_acc: 0.5833\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9378 - acc: 0.6178 - val_loss: 0.9067 - val_acc: 0.6198\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8373 - acc: 0.6439 - val_loss: 0.9656 - val_acc: 0.5104\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8741 - acc: 0.6513 - val_loss: 0.8363 - val_acc: 0.6250\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7682 - acc: 0.6539 - val_loss: 0.8332 - val_acc: 0.6094\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8448 - acc: 0.6295 - val_loss: 0.7879 - val_acc: 0.6562\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7310 - acc: 0.6748 - val_loss: 0.7813 - val_acc: 0.6042\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7048 - acc: 0.6647 - val_loss: 0.7401 - val_acc: 0.6302\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6737 - acc: 0.6742 - val_loss: 0.7593 - val_acc: 0.6146\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6742 - acc: 0.6507 - val_loss: 0.7339 - val_acc: 0.6250\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7139 - acc: 0.6650 - val_loss: 0.8274 - val_acc: 0.5625\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6514 - acc: 0.6700 - val_loss: 0.7584 - val_acc: 0.6510\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7337 - acc: 0.6450 - val_loss: 0.7281 - val_acc: 0.6302\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6523 - acc: 0.6751 - val_loss: 0.7489 - val_acc: 0.6562\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6768 - acc: 0.6630 - val_loss: 0.7149 - val_acc: 0.6615\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6282 - acc: 0.7154 - val_loss: 0.6893 - val_acc: 0.6615\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5854 - acc: 0.7317 - val_loss: 0.6939 - val_acc: 0.6302\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6167 - acc: 0.7130 - val_loss: 0.6887 - val_acc: 0.6354\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6506 - acc: 0.6905 - val_loss: 0.6755 - val_acc: 0.6615\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6242 - acc: 0.6738 - val_loss: 0.7757 - val_acc: 0.6875\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6498 - acc: 0.6997 - val_loss: 0.6820 - val_acc: 0.6510\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6021 - acc: 0.6834 - val_loss: 0.6656 - val_acc: 0.6562\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - acc: 0.7510 - val_loss: 0.6990 - val_acc: 0.6615\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5834 - acc: 0.7311 - val_loss: 0.6681 - val_acc: 0.6719\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - acc: 0.6965 - val_loss: 0.6535 - val_acc: 0.7031\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - acc: 0.7176 - val_loss: 0.7034 - val_acc: 0.6979\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6003 - acc: 0.7201 - val_loss: 0.6795 - val_acc: 0.6458\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5800 - acc: 0.7089 - val_loss: 0.6576 - val_acc: 0.6354\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.7519 - val_loss: 0.6421 - val_acc: 0.6823\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5281 - acc: 0.7236 - val_loss: 0.6509 - val_acc: 0.6667\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - acc: 0.7406 - val_loss: 0.6368 - val_acc: 0.6667\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5514 - acc: 0.7132 - val_loss: 0.6545 - val_acc: 0.6667\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - acc: 0.7153 - val_loss: 0.6325 - val_acc: 0.7031\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.6514 - val_loss: 0.6446 - val_acc: 0.6927\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5260 - acc: 0.7319 - val_loss: 0.6363 - val_acc: 0.6667\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5083 - acc: 0.7440 - val_loss: 0.6951 - val_acc: 0.6302\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5323 - acc: 0.7303 - val_loss: 0.7340 - val_acc: 0.5938\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - acc: 0.6994 - val_loss: 0.6486 - val_acc: 0.6979\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - acc: 0.7502 - val_loss: 0.6416 - val_acc: 0.6771\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - acc: 0.7273 - val_loss: 0.6448 - val_acc: 0.6562\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5246 - acc: 0.7404 - val_loss: 0.6429 - val_acc: 0.6771\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5305 - acc: 0.7349 - val_loss: 0.7049 - val_acc: 0.6354\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5301 - acc: 0.7355 - val_loss: 0.6661 - val_acc: 0.6354\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - acc: 0.7539 - val_loss: 0.6430 - val_acc: 0.6510\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - acc: 0.7534 - val_loss: 0.6184 - val_acc: 0.6927\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - acc: 0.7447 - val_loss: 0.6626 - val_acc: 0.6406\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - acc: 0.7632 - val_loss: 0.6352 - val_acc: 0.6823\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5323 - acc: 0.7206 - val_loss: 0.6646 - val_acc: 0.6719\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - acc: 0.7130 - val_loss: 0.6292 - val_acc: 0.7083\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - acc: 0.7719 - val_loss: 0.6328 - val_acc: 0.6615\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - acc: 0.7967 - val_loss: 0.6492 - val_acc: 0.6979\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - acc: 0.7637 - val_loss: 0.6700 - val_acc: 0.7188\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5234 - acc: 0.7411 - val_loss: 0.6222 - val_acc: 0.7083\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - acc: 0.7369 - val_loss: 0.6216 - val_acc: 0.6562\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - acc: 0.7549 - val_loss: 0.6550 - val_acc: 0.7083\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - acc: 0.7176 - val_loss: 0.6869 - val_acc: 0.7031\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5388 - acc: 0.7352 - val_loss: 0.6395 - val_acc: 0.7083\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - acc: 0.7630 - val_loss: 0.6344 - val_acc: 0.6615\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - acc: 0.7874 - val_loss: 0.6592 - val_acc: 0.7292\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - acc: 0.7570 - val_loss: 0.6138 - val_acc: 0.6719\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5337 - acc: 0.7161 - val_loss: 0.6944 - val_acc: 0.6354\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5918 - acc: 0.6934 - val_loss: 0.6546 - val_acc: 0.6875\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - acc: 0.7375 - val_loss: 0.6380 - val_acc: 0.6615\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - acc: 0.7632 - val_loss: 0.6812 - val_acc: 0.7083\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - acc: 0.7525 - val_loss: 0.6263 - val_acc: 0.6719\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - acc: 0.7936 - val_loss: 0.6412 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - acc: 0.8017 - val_loss: 0.6590 - val_acc: 0.6979\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - acc: 0.7277 - val_loss: 0.7037 - val_acc: 0.7083\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5956 - acc: 0.7205 - val_loss: 0.6738 - val_acc: 0.6302\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - acc: 0.7844 - val_loss: 0.6602 - val_acc: 0.6979\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - acc: 0.7724 - val_loss: 0.6570 - val_acc: 0.6875\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - acc: 0.7847 - val_loss: 0.6482 - val_acc: 0.6562\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - acc: 0.7700 - val_loss: 0.6637 - val_acc: 0.7031\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5139 - acc: 0.7699 - val_loss: 0.6255 - val_acc: 0.6875\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - acc: 0.7783 - val_loss: 0.6556 - val_acc: 0.6823\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - acc: 0.7391 - val_loss: 0.6333 - val_acc: 0.6927\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - acc: 0.7720 - val_loss: 0.6331 - val_acc: 0.7083\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - acc: 0.7858 - val_loss: 0.6233 - val_acc: 0.6615\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - acc: 0.7753 - val_loss: 0.6252 - val_acc: 0.7188\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - acc: 0.7604 - val_loss: 0.6452 - val_acc: 0.7031\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - acc: 0.7175 - val_loss: 0.8892 - val_acc: 0.5365\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5634 - acc: 0.7240 - val_loss: 0.6346 - val_acc: 0.6823\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - acc: 0.7790 - val_loss: 0.6836 - val_acc: 0.6823\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - acc: 0.7948 - val_loss: 0.6277 - val_acc: 0.7188\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5460 - acc: 0.7243 - val_loss: 0.6139 - val_acc: 0.7083\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - acc: 0.7802 - val_loss: 0.6478 - val_acc: 0.6719\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - acc: 0.7578 - val_loss: 0.6329 - val_acc: 0.6979\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - acc: 0.7923 - val_loss: 0.6293 - val_acc: 0.6979\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - acc: 0.7857 - val_loss: 0.6346 - val_acc: 0.6823\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - acc: 0.7615 - val_loss: 0.6086 - val_acc: 0.7135\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - acc: 0.7698 - val_loss: 0.6182 - val_acc: 0.6927\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - acc: 0.7878 - val_loss: 0.6239 - val_acc: 0.6771\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - acc: 0.7759 - val_loss: 0.6519 - val_acc: 0.6562\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - acc: 0.8084 - val_loss: 0.6366 - val_acc: 0.6719\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - acc: 0.7948 - val_loss: 0.6159 - val_acc: 0.6979\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - acc: 0.7760 - val_loss: 0.6136 - val_acc: 0.7031\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - acc: 0.7476 - val_loss: 0.6851 - val_acc: 0.6354\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - acc: 0.7714 - val_loss: 0.6387 - val_acc: 0.7135\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - acc: 0.7829 - val_loss: 0.6335 - val_acc: 0.6979\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - acc: 0.7672 - val_loss: 0.6067 - val_acc: 0.7135\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - acc: 0.7821 - val_loss: 0.6791 - val_acc: 0.6979\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - acc: 0.7740 - val_loss: 0.6498 - val_acc: 0.6719\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - acc: 0.7920 - val_loss: 0.6383 - val_acc: 0.6979\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - acc: 0.7885 - val_loss: 0.6804 - val_acc: 0.7188\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - acc: 0.7296 - val_loss: 0.6137 - val_acc: 0.7083\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - acc: 0.7804 - val_loss: 0.6277 - val_acc: 0.7031\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - acc: 0.8171 - val_loss: 0.6213 - val_acc: 0.7031\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - acc: 0.7888 - val_loss: 0.6455 - val_acc: 0.6875\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.7604 - val_loss: 0.6288 - val_acc: 0.6979\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - acc: 0.8034 - val_loss: 0.7875 - val_acc: 0.5833\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5135 - acc: 0.7535 - val_loss: 0.6583 - val_acc: 0.6927\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - acc: 0.8091 - val_loss: 0.6424 - val_acc: 0.6615\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - acc: 0.7809 - val_loss: 0.6159 - val_acc: 0.6979\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - acc: 0.7915 - val_loss: 0.6327 - val_acc: 0.6667\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - acc: 0.8078 - val_loss: 0.6096 - val_acc: 0.7083\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - acc: 0.8095 - val_loss: 0.6211 - val_acc: 0.6979\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - acc: 0.8141 - val_loss: 0.6270 - val_acc: 0.6771\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - acc: 0.7730 - val_loss: 0.6328 - val_acc: 0.6771\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - acc: 0.7684 - val_loss: 0.6137 - val_acc: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - acc: 0.7979 - val_loss: 0.6502 - val_acc: 0.6771\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - acc: 0.8135 - val_loss: 0.6006 - val_acc: 0.7188\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.7971 - val_loss: 0.6682 - val_acc: 0.6406\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - acc: 0.7789 - val_loss: 0.6119 - val_acc: 0.6875\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - acc: 0.8018 - val_loss: 0.6649 - val_acc: 0.6719\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - acc: 0.7712 - val_loss: 0.6839 - val_acc: 0.6979\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - acc: 0.7660 - val_loss: 0.6546 - val_acc: 0.6562\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4973 - acc: 0.7753 - val_loss: 0.6773 - val_acc: 0.6510\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.7942 - val_loss: 0.6436 - val_acc: 0.7031\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - acc: 0.7517 - val_loss: 0.6517 - val_acc: 0.6823\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - acc: 0.7762 - val_loss: 0.6283 - val_acc: 0.6927\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - acc: 0.7706 - val_loss: 0.6581 - val_acc: 0.6719\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - acc: 0.7997 - val_loss: 0.6539 - val_acc: 0.6875\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - acc: 0.7858 - val_loss: 0.6461 - val_acc: 0.6927\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - acc: 0.7681 - val_loss: 0.6680 - val_acc: 0.6562\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - acc: 0.7664 - val_loss: 0.6436 - val_acc: 0.6875\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - acc: 0.7956 - val_loss: 0.6239 - val_acc: 0.7031\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - acc: 0.7841 - val_loss: 0.6671 - val_acc: 0.6979\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - acc: 0.8180 - val_loss: 0.7922 - val_acc: 0.6719\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - acc: 0.7502 - val_loss: 0.6821 - val_acc: 0.6719\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - acc: 0.7945 - val_loss: 0.6657 - val_acc: 0.6719\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - acc: 0.8065 - val_loss: 0.6325 - val_acc: 0.7135\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - acc: 0.7939 - val_loss: 0.6546 - val_acc: 0.6615\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5103 - acc: 0.7709 - val_loss: 0.7097 - val_acc: 0.6719\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - acc: 0.7730 - val_loss: 0.6809 - val_acc: 0.7031\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - acc: 0.7773 - val_loss: 0.6565 - val_acc: 0.6823\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - acc: 0.8156 - val_loss: 0.6425 - val_acc: 0.6719\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - acc: 0.8093 - val_loss: 0.7270 - val_acc: 0.6823\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - acc: 0.7937 - val_loss: 0.6133 - val_acc: 0.7031\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.7960 - val_loss: 0.6571 - val_acc: 0.6771\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - acc: 0.8146 - val_loss: 0.6508 - val_acc: 0.6615\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - acc: 0.7842 - val_loss: 0.6578 - val_acc: 0.7031\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - acc: 0.7877 - val_loss: 0.7045 - val_acc: 0.7031\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - acc: 0.8072 - val_loss: 0.6404 - val_acc: 0.7031\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - acc: 0.8050 - val_loss: 0.7162 - val_acc: 0.6146\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4783 - acc: 0.7638 - val_loss: 0.6330 - val_acc: 0.6875\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - acc: 0.7668 - val_loss: 0.6517 - val_acc: 0.7135\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - acc: 0.8191 - val_loss: 0.6166 - val_acc: 0.6927\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - acc: 0.7978 - val_loss: 0.6280 - val_acc: 0.6823\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - acc: 0.8280 - val_loss: 0.6988 - val_acc: 0.7031\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - acc: 0.7790 - val_loss: 0.7155 - val_acc: 0.6458\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - acc: 0.7826 - val_loss: 0.6464 - val_acc: 0.7083\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - acc: 0.7581 - val_loss: 0.6451 - val_acc: 0.6927\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - acc: 0.8021 - val_loss: 0.6104 - val_acc: 0.6719\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - acc: 0.8120 - val_loss: 0.6408 - val_acc: 0.6771\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - acc: 0.7902 - val_loss: 0.6084 - val_acc: 0.6979\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - acc: 0.7868 - val_loss: 0.6404 - val_acc: 0.6823\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4035 - acc: 0.8401 - val_loss: 0.6096 - val_acc: 0.6823\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - acc: 0.8053 - val_loss: 0.6705 - val_acc: 0.6979\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - acc: 0.7557 - val_loss: 0.6552 - val_acc: 0.6979\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - acc: 0.8037 - val_loss: 0.7625 - val_acc: 0.6354\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - acc: 0.7968 - val_loss: 0.6390 - val_acc: 0.7083\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - acc: 0.7945 - val_loss: 0.7035 - val_acc: 0.6667\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - acc: 0.7728 - val_loss: 0.6770 - val_acc: 0.6979\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - acc: 0.7839 - val_loss: 0.6342 - val_acc: 0.6927\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - acc: 0.8067 - val_loss: 0.6723 - val_acc: 0.6458\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4012 - acc: 0.8387 - val_loss: 0.6431 - val_acc: 0.6823\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - acc: 0.7923 - val_loss: 0.6206 - val_acc: 0.7083\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - acc: 0.7831 - val_loss: 0.6361 - val_acc: 0.6927\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - acc: 0.8179 - val_loss: 0.6202 - val_acc: 0.6823\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - acc: 0.8095 - val_loss: 0.6547 - val_acc: 0.6979\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - acc: 0.7952 - val_loss: 0.6573 - val_acc: 0.6927\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - acc: 0.8308 - val_loss: 0.6433 - val_acc: 0.6667\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - acc: 0.8040 - val_loss: 0.6251 - val_acc: 0.6979\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - acc: 0.8099 - val_loss: 0.6250 - val_acc: 0.7083\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - acc: 0.8128 - val_loss: 0.6807 - val_acc: 0.6510\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - acc: 0.7387 - val_loss: 0.6430 - val_acc: 0.7083\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - acc: 0.8090 - val_loss: 0.6190 - val_acc: 0.7031\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - acc: 0.8269 - val_loss: 0.6226 - val_acc: 0.6823\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - acc: 0.7919 - val_loss: 0.6562 - val_acc: 0.6562\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - acc: 0.8214 - val_loss: 0.6245 - val_acc: 0.6927\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - acc: 0.8385 - val_loss: 0.6336 - val_acc: 0.6719\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - acc: 0.8231 - val_loss: 0.6480 - val_acc: 0.6823\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3933 - acc: 0.8274 - val_loss: 0.7301 - val_acc: 0.6562\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - acc: 0.7701 - val_loss: 0.6935 - val_acc: 0.6771\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - acc: 0.8111 - val_loss: 0.6688 - val_acc: 0.7135\n"
     ]
    }
   ],
   "source": [
    "# Add the validation_data=(X_test, Y_test) attribute to .fit() method\n",
    "history =  model2_fitted = model2.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the dense model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_92 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 841\n",
      "Trainable params: 841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 2 Accuracy with added dense layers:  0.7135416865348816\n",
      "Model 2 Loss with added dense layers:  0.6688409447669983\n"
     ]
    }
   ],
   "source": [
    "print(model2.summary())\n",
    "\n",
    "loss, accuracy = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 2 Accuracy with added dense layers: \", accuracy)\n",
    "print(\"Model 2 Loss with added dense layers: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the accuracy for training and validation in the same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "Ucrl_X9eDflQ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Plot of Model Accuracy on Train and Validation Datasets')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19SYVY4DH7OW"
   },
   "source": [
    "## Normalize the data before feeding the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential() # create a Sequential model\n",
    "\n",
    "model3.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
    "\n",
    "# Add more Dense layers to the existing code\n",
    "model3.add(Dense(30, activation='relu')) \n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid')) # output layer (WHY 'sigmoid function!!!')\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 920us/step - loss: 0.7003 - acc: 0.5780\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.6453 - acc: 0.6967\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.5890 - acc: 0.7418\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5534 - acc: 0.7498\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.5288 - acc: 0.7611\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5408 - acc: 0.7355\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.5042 - acc: 0.7588\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.5075 - acc: 0.7623\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4843 - acc: 0.7751\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4887 - acc: 0.7777\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.5165 - acc: 0.7477\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4402 - acc: 0.8219\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4539 - acc: 0.7919\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4561 - acc: 0.7706\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4567 - acc: 0.8062\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4482 - acc: 0.7805\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4386 - acc: 0.7829\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4591 - acc: 0.7898\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4367 - acc: 0.7942\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4493 - acc: 0.7865\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4432 - acc: 0.8101\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4604 - acc: 0.7937\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4395 - acc: 0.7798\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4304 - acc: 0.7819\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4429 - acc: 0.7831\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4484 - acc: 0.7985\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4624 - acc: 0.7775\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4347 - acc: 0.7809\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4238 - acc: 0.7927\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4016 - acc: 0.8079\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4195 - acc: 0.8001\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4201 - acc: 0.8033\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4165 - acc: 0.8172\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4063 - acc: 0.8005\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4165 - acc: 0.8109\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4013 - acc: 0.8229\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4192 - acc: 0.7787\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.3886 - acc: 0.8399\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4333 - acc: 0.7871\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4305 - acc: 0.8015\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.3979 - acc: 0.8342\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4096 - acc: 0.8009\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.3840 - acc: 0.8235\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4147 - acc: 0.8082\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.3850 - acc: 0.8334\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4047 - acc: 0.8003\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.3977 - acc: 0.8212\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4036 - acc: 0.8109\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4155 - acc: 0.7926\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.3858 - acc: 0.8282\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.3557 - acc: 0.8472\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4060 - acc: 0.8020\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.3957 - acc: 0.7975\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3860 - acc: 0.8103\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.3777 - acc: 0.8279\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4034 - acc: 0.8073\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.3933 - acc: 0.8129\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.3858 - acc: 0.8223\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3713 - acc: 0.8121\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.3863 - acc: 0.8242\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.3872 - acc: 0.8329\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.3904 - acc: 0.8158\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3706 - acc: 0.8199\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.3644 - acc: 0.8459\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 814us/step - loss: 0.3806 - acc: 0.8359\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3844 - acc: 0.8199\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3677 - acc: 0.8315\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.3976 - acc: 0.8135\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.3816 - acc: 0.8258\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.3774 - acc: 0.8248\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.3821 - acc: 0.8151\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.3941 - acc: 0.8261\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3667 - acc: 0.8360\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3747 - acc: 0.8376\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 759us/step - loss: 0.3412 - acc: 0.8592\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.3622 - acc: 0.8156\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.3307 - acc: 0.8606\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3612 - acc: 0.8172\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.3569 - acc: 0.8422\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.3867 - acc: 0.8265\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 791us/step - loss: 0.3482 - acc: 0.8478\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.3772 - acc: 0.8063\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3418 - acc: 0.8380\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.3375 - acc: 0.8523\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 964us/step - loss: 0.3612 - acc: 0.8283\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3857 - acc: 0.8101\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3740 - acc: 0.8159\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.3928 - acc: 0.8164\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.3712 - acc: 0.8218\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.3706 - acc: 0.8183\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.3339 - acc: 0.8478\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.3581 - acc: 0.8329\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.3459 - acc: 0.8391\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 803us/step - loss: 0.3686 - acc: 0.8300\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.3287 - acc: 0.8558\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.3524 - acc: 0.8251\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.3610 - acc: 0.8385\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.3488 - acc: 0.8375\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.3314 - acc: 0.8400\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.3758 - acc: 0.8111\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.3277 - acc: 0.8537\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.3473 - acc: 0.8436\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.3139 - acc: 0.8613\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 807us/step - loss: 0.3346 - acc: 0.8563\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.3368 - acc: 0.8351\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 794us/step - loss: 0.3227 - acc: 0.8606\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.3267 - acc: 0.8549\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.3304 - acc: 0.8472\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.3419 - acc: 0.8559\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.3463 - acc: 0.8283\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.3440 - acc: 0.8281\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.3171 - acc: 0.8742\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.3247 - acc: 0.8670\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.3279 - acc: 0.8588\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 724us/step - loss: 0.3069 - acc: 0.8588\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 648us/step - loss: 0.3259 - acc: 0.8511\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.3242 - acc: 0.8496\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 716us/step - loss: 0.3159 - acc: 0.8521\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 699us/step - loss: 0.3341 - acc: 0.8535\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 772us/step - loss: 0.3071 - acc: 0.8630\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 782us/step - loss: 0.3163 - acc: 0.8586\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 780us/step - loss: 0.3168 - acc: 0.8490\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.3296 - acc: 0.8514\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.3077 - acc: 0.8737\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 793us/step - loss: 0.3062 - acc: 0.8647\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 758us/step - loss: 0.3018 - acc: 0.8659\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.2953 - acc: 0.8706\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 710us/step - loss: 0.2925 - acc: 0.8829\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 791us/step - loss: 0.3197 - acc: 0.8581\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 684us/step - loss: 0.3003 - acc: 0.8622\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 702us/step - loss: 0.3171 - acc: 0.8612\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 811us/step - loss: 0.3044 - acc: 0.8647\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.3012 - acc: 0.8845\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 721us/step - loss: 0.2990 - acc: 0.8601\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 712us/step - loss: 0.3366 - acc: 0.8378\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 767us/step - loss: 0.2929 - acc: 0.8814\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 755us/step - loss: 0.3224 - acc: 0.8515\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.3159 - acc: 0.8639\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 718us/step - loss: 0.3061 - acc: 0.8757\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.2982 - acc: 0.8606\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 694us/step - loss: 0.2882 - acc: 0.8893\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.2944 - acc: 0.8857\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 763us/step - loss: 0.2833 - acc: 0.8730\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 747us/step - loss: 0.3024 - acc: 0.8695\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.2957 - acc: 0.8663\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.2679 - acc: 0.8880\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 742us/step - loss: 0.2645 - acc: 0.8959\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 647us/step - loss: 0.2947 - acc: 0.8750\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.2712 - acc: 0.8832\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 632us/step - loss: 0.2858 - acc: 0.8673\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 749us/step - loss: 0.2905 - acc: 0.8740\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 751us/step - loss: 0.2740 - acc: 0.8852\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 748us/step - loss: 0.2705 - acc: 0.8843\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 698us/step - loss: 0.2877 - acc: 0.8743\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 773us/step - loss: 0.2679 - acc: 0.8819\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 812us/step - loss: 0.2990 - acc: 0.8678\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 757us/step - loss: 0.2884 - acc: 0.8637\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 754us/step - loss: 0.2915 - acc: 0.8674\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 764us/step - loss: 0.2873 - acc: 0.8617\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.2881 - acc: 0.8643\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.2908 - acc: 0.8668\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.2646 - acc: 0.8912\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.2923 - acc: 0.8485\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.2488 - acc: 0.8860\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.2776 - acc: 0.8680\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.3139 - acc: 0.8514\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.2749 - acc: 0.8774\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 874us/step - loss: 0.2890 - acc: 0.8669\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2843 - acc: 0.8660\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.2915 - acc: 0.8651\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.3002 - acc: 0.8567\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 795us/step - loss: 0.2778 - acc: 0.8699\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 719us/step - loss: 0.2571 - acc: 0.8904\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 774us/step - loss: 0.2653 - acc: 0.8697\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 792us/step - loss: 0.2899 - acc: 0.8700\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 668us/step - loss: 0.2709 - acc: 0.8844\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 648us/step - loss: 0.2586 - acc: 0.8808\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 637us/step - loss: 0.2737 - acc: 0.8701\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 647us/step - loss: 0.2654 - acc: 0.8848\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 765us/step - loss: 0.2752 - acc: 0.8776\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 759us/step - loss: 0.2586 - acc: 0.8903\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.2508 - acc: 0.8877\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.2624 - acc: 0.8927\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 788us/step - loss: 0.2818 - acc: 0.8670\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 817us/step - loss: 0.2885 - acc: 0.8725\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 762us/step - loss: 0.2714 - acc: 0.8710\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 792us/step - loss: 0.2578 - acc: 0.8779\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 704us/step - loss: 0.2735 - acc: 0.8707\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 671us/step - loss: 0.2755 - acc: 0.8774\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 645us/step - loss: 0.2622 - acc: 0.8669\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 713us/step - loss: 0.2635 - acc: 0.8713\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 736us/step - loss: 0.2717 - acc: 0.8786\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 712us/step - loss: 0.2786 - acc: 0.8862\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.2635 - acc: 0.8721\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 780us/step - loss: 0.2687 - acc: 0.8772\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 787us/step - loss: 0.2502 - acc: 0.8963\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 800us/step - loss: 0.2456 - acc: 0.8926\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 749us/step - loss: 0.2424 - acc: 0.8883\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.2618 - acc: 0.8760\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.2736 - acc: 0.8651\n"
     ]
    }
   ],
   "source": [
    "# The returned history object holds a record of the loss values and metric values during training\n",
    "model3_fitted = model3.fit(X_train, Y_train, epochs=200, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of the model 3 with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 20)                180       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 841\n",
      "Trainable params: 841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Model 3 Accuracy after data normalization:  0.7239583134651184\n",
      "Model 3 Loss after data normalization:  0.6256093978881836\n"
     ]
    }
   ],
   "source": [
    "print(model3.summary())\n",
    "\n",
    "loss, accuracy = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"\\nModel 3 Accuracy after data normalization: \", accuracy)\n",
    "print(\"Model 3 Loss after data normalization: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_Lesson_1_(diabetes).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
